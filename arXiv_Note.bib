@article{JahnRendsvigGithub2,
 title        = {{Towards Detecting Inauthentic Coordination in Twitter Likes Data}},
 author       = {{Jahn Laura and Rendsvig, Rasmus~K.}},
 year         = 2023,
 journal      = {arXiv},
 url          = {https://doi.org/10.1145/2675133.2675208},
}


@book{LauraThesis,
	title        = {{Curbing Amplification Online: Towards Improving the Quality of Information Spread on Social Media Using Agent-Based Models and Twitter Data}},
	author       = {{Jahn, Laura}},
	year         = 2023,
	publisher    = {PhD Thesis, University of Copenhagen}
}

@article{JahnRendsvigTwitterLikesCIB,
 title        = {{Towards Detecting Inauthentic Coordination in Twitter Likes Data}},
 author       = {{Jahn Luara and Rendsvig, Rasmus~K.}},
 year         = 2023,
 journal      = {arXiv},
 doi          = {https://doi.org/10.1145/2675133.2675208},
}

@report{Scalablebotdetection,
	title        = {{Scalable and Generalizable Social Bot Detection through Data Selection}},
	author       = {{Kai-Cheng Yang and Onur Varol and Pik-Mai Hui and Filippo Menczer}},
	url          = {www.aaai.org},
	abstract     = {Efficient and reliable social bot classification is crucial for detecting information manipulation on social media. Despite rapid development, state-of-the-art bot detection models still face generalization and scalability challenges, which greatly limit their applications. In this paper we propose a framework that uses minimal account metadata, enabling efficient analysis that scales up to handle the full stream of public tweets of Twitter in real time. To ensure model accuracy, we build a rich collection of labeled datasets for training and validation. We deploy a strict validation system so that model performance on unseen datasets is also optimized, in addition to traditional cross-validation. We find that strategically selecting a subset of training data yields better model accuracy and generalization than exhaustively training on all available data. Thanks to the simplicity of the proposed model, its logic can be interpreted to provide insights into social bot characteristics.},
	keywords     = {Applications}
}
@inproceedings{2018Bhuiyan_FeedReflectgameintervention,
	title        = {{FeedReflect: A Tool for Nudging Users to Assess News Credibility on Twitter}},
	author       = {{Bhuiyan, Md Momen and Zhang, Kexin and Vick, Kelsey and Horning, Michael A. and Mitra, Tanushree}},
	year         = 2018,
	booktitle    = {Companion of the 2018 ACM Conference on Computer Supported Cooperative Work and Social Computing},
	location     = {Jersey City, NJ, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CSCW '18},
	pages        = {205--208},
	doi          = {10.1145/3272973.3274056},
	isbn         = 9781450360180,
	url          = {https://doi.org/10.1145/3272973.3274056},
	abstract     = {In recent years, the emergence of fake news outlets has drawn out the importance of news literacy. This is particularly critical in social media where the flood of information makes it difficult for people to assess the veracity of the false stories from such deceitful sources. Therefore, people oftentimes fail to look skeptically at these stories. We explore a way to circumvent this problem by nudging users into making conscious assessments of what online contents are credible. For this purpose, we developed FeedReflect, a browser extension. The extension nudges users to pay more attention and uses reflective questions to engage in news credibility assessment on Twitter. We recruited a small number of university students to use this tool on Twitter. Both qualitative and quantitative analysis of the study suggests the extension helped people accurately assess the credibility of news. This implies FeedReflect can be used for the broader audience to improve online news literacy.},
	numpages     = 4,
	keywords     = {social media, reflection, news credibility, user engagement, feedreflect}
}
@article{Abokhodair2015,
	title        = {{Dissecting a social Botnet: Growth, content and influence in Twitter}},
	author       = {{Abokhodair, Norah and Yoo, Daisy and McDonald, David W.}},
	year         = 2015,
	journal      = {CSCW 2015 - Proceedings of the 2015 ACM International Conference on Computer-Supported Cooperative Work and Social Computing},
	pages        = {839--851},
	doi          = {https://doi.org/10.1145/2675133.2675208},
	isbn         = 9781450329224,
	keywords     = {Arab Spring,Automated Social Actor,Botnet,Bots,Social Computing,Twitter}
}
@techreport{acemoglu2021misinformation,
	title        = {{Misinformation: Strategic sharing, homophily, and endogenous echo chambers}},
	author       = {{Acemoglu, Daron and Ozdaglar, Asuman and Siderius, James}},
	year         = 2021,
	institution  = {National Bureau of Economic Research}
}
@inproceedings{aggarwal2015Twitterfakefol,
	title        = {{What they do in shadows: Twitter underground follower market}},
	author       = {{Aggarwal, Anupama and Kumaraguru, Ponnurangam}},
	year         = 2015,
	booktitle    = {2015 13th Annual Conference on Privacy, Security and Trust (PST)},
	pages        = {93--100},
	doi          = {https://doi.org/10.1109/PST.2015.7232959},
	organization = {IEEE}
}
@article{Ahmed2013,
	title        = {{A generic statistical approach for spam detection in Online Social Networks}},
	author       = {{Ahmed, Faraz and Abulaish, Muhammad}},
	year         = 2013,
	month        = 6,
	journal      = {Computer Communications},
	publisher    = {Elsevier B.V.},
	volume       = 36,
	number       = {10-11},
	pages        = {1120--1129},
	doi          = {https://doi.org/10.1016/j.comcom.2013.04.004},
	issn         = {01403664},
	keywords     = {Data mining,Social network analysis,Social network security,Spam campaign identification,Spam profile identification},
	abstract     = {In this paper, we present a generic statistical approach to identify spam profiles on Online Social Networks (OSNs). Our study is based on real datasets containing both normal and spam profiles crawled from Facebook and Twitter networks. We have identified a set of 14 generic statistical features to identify spam profiles. The identified features are common to both Facebook and Twitter networks. For classification task, we have used three different classification algorithms - naïve Bayes, Jrip, and J48, and evaluated them on both individual and combined datasets to establish the discriminative property of the identified features. The results obtained on a combined dataset has detection rate (DR) as 0.957 and false positive rate (FPR) as 0.048, whereas on Facebook dataset the DR and FPR values are 0.964 and 0.089, respectively, and that on Twitter dataset the DR and FPR values are 0.976 and 0.075, respectively. We have also analyzed the contribution of each individual feature towards the detection accuracy of spam profiles. Thereafter, we have considered 7 most discriminative features and proposed a clustering-based approach to identify spam campaigns on Facebook and Twitter networks. © 2013 Elsevier B.V. All rights reserved.},
	issue        = {10-11}
}
@inproceedings{AlKhateebAgrawal2015botnet,
	title        = {{Examining botnet behaviors for propaganda dissemination: A case study of isil's beheading videos-based propaganda}},
	author       = {{Al-Khateeb, Samer and Agarwal, Nitin}},
	year         = 2015,
	booktitle    = {2015 ieee international conference on data mining workshop (icdmw)},
	pages        = {51--57},
	organization = {IEEE}
}
@article{AlKhateebAgrawal2016_coord,
	title        = {{UNDERSTANDING STRATEGIC INFORMATION MANOEUVRES IN NETWORK MEDIA TO ADVANCE CYBER OPERATIONS: A CASE STUDY ANALYSING PRO-RUSSIAN SEPARATISTS'CYBER INFORMATION OPERATIONS IN CRIMEAN WATER CRISIS.}},
	author       = {{Al-Khateeb, Samer and Agarwal, Nitin}},
	year         = 2016,
	journal      = {Journal on Baltic Security},
	volume       = 2,
	number       = 1
}
@article{alshaabi2021growing,
	title        = {{The growing amplification of social media: Measuring temporal and social contagion dynamics for over 150 languages on Twitter for 2009--2020}},
	author       = {{Alshaabi, Thayer and Dewhurst, David Rushing and Minot, Joshua R and Arnold, Michael V and Adams, Jane L and Danforth, Christopher M and Dodds, Peter Sheridan}},
	year         = 2021,
	journal      = {EPJ data science},
	publisher    = {Springer Berlin Heidelberg},
	volume       = 10,
	number       = 1,
	pages        = 15
}
@article{altay2022misinformation,
	title        = {{Misinformation Is a Threat Because (Other) People are Gullible}},
	author       = {{Altay, Sacha and Acerbi, Alberto}},
	year         = 2022,
	publisher    = {PsyArXiv}
}
@article{Anderson1997,
	title        = {{Information Cascades in the Laboratory}},
	author       = {{Anderson, Lisa R. and Holt, Charles A.}},
	year         = 1997,
	journal      = {The American Economic Review},
	volume       = 87,
	number       = 5,
	pages        = {847--862}
}
@article{angere2010knowledge,
	title        = {{Knowledge in a social network}},
	author       = {{Angere, Staffan}},
	year         = 2010,
	journal      = {Synthese},
	pages        = {167--203}
}
@article{Aral2019,
	title        = {{Protecting elections from social media manipulation}},
	author       = {{Aral, Sinan and Eckles, Dean}},
	year         = 2019,
	journal      = {Science},
	volume       = 365,
	number       = 6456,
	pages        = {858--861},
	issn         = 10959203
}
@article{avram2020exposure,
	title        = {{Exposure to social engagement metrics increases vulnerability to misinformation}},
	author       = {{Avram, Mihai and Micallef, Nicholas and Patil, Sameer and Menczer, Filippo}},
	year         = {July 2020},
	journal      = {The Harvard Kennedy School Misinformation Review},
	volume       = 1,
	number       = 5,
	doi          = {https://doi.org/10.37016/mr-2020-033}
}
@article{BaltagChristoffRendsvigSmets2018,
	title        = {{Dynamic Epistemic Logic of Diffusion and Prediction in Threshold Models}},
	author       = {{Baltag, Alexandru and Christoff, Zo\'{e} and Rendsvig, Rasmus~K. and Smets, Sonja}},
	year         = 2018,
	journal      = {Studia Logica},
	volume       = {online first}
}
@article{Banerjee1992,
	title        = {{A Simple Model of Herd Behavior}},
	author       = {{Banerjee, Abhijit V.}},
	year         = 1992,
	journal      = {The Quarterly Journal of Economics},
	volume       = 107,
	number       = 3,
	pages        = {797--817}
}
@article{barabasi1999emergence,
	title        = {{Emergence of scaling in random networks}},
	author       = {{Barab\'a}si, Albert-L{\'a}szl{\'o} and Albert, R{\'e}ka}}}}},
	year         = 1999,
	journal      = {science},
	publisher    = {American Association for the Advancement of Science},
	volume       = 286,
	number       = 5439,
	pages        = {509--512}
}
@article{bates2017friction,
	title        = {{The politics of data friction}},
	author       = {{Bates, Jo}},
	year         = 2017,
	journal      = {Journal of Documentation},
	publisher    = {Emerald Publishing Limited}
}
@article{BazzazAbkenar2021,
	title        = {{A hybrid classification method for Twitter spam detection based on differential evolution and random forest}},
	author       = {{Bazzaz Abkenar, Sepideh and Mahdipour, Ebrahim and Jameii, Seyed Mahdi and Haghi Kashani, Mostafa}},
	year         = 2021,
	journal      = {Concurrency Computation},
	number       = {March},
	pages        = {1--20},
	issn         = 15320634,
	keywords     = {Twitter,imbalanced dataset,machine learning,social networks,spam}
}
@article{Beatson2021,
	title        = {{Automation on Twitter: Measuring the Effectiveness of Approaches to Bot Detection}},
	author       = {{Beatson, Oliver and Gibson, Rachel and Cunill, Marta Cantijoch and Elliot, Mark}},
	year         = 2021,
	journal      = {Social Science Computer Review},
	publisher    = {SAGE Publications Inc.},
	pages        = {1--20},
	doi          = {https://doi.org/10.1177/08944393211034991},
	issn         = 15528286,
	keywords     = {OSINT,Twitter,bots,disinformation,political astroturfing,social media},
	abstract     = {The effectiveness of approaches to bot detection varies, with real-time detection being almost impossible. As a result, this article argues that the general Twitter using public cannot be expected to judge which accounts are bots with certainty and therefore do not know to what extent they are being manipulated online. In this article, the challenge of detecting bots and fake accounts is demonstrated by constructing two distinct methods to bot detection. The first method takes a fixed criteria-based approach, by building on commonly cited identifiers for bots. The second method takes a more flexible, investigative approach in order to uncover bots involved in coordinated efforts to influence online debates. As well as profiling the specific mechanics of how each one operates, we argue that they can be compared against an evaluative framework that specifies a set of key criteria that bot detection methods should meet in order to perform. Here, we identify four key criteria on which these methods can be evaluated and then examine how they perform in terms of the key criteria of accuracy. The results of these methods are then compared and cross-checked against an existing and widely used bot detection service. The findings show that different bot detection methods can present significantly different results and that only confirmation from Twitter, through suspensions or announcements, can truly allow users to know whether an account is a bot or not. We argue that this development could have a significant effect on the level of trust that social media users have both in the information they receive through social media and also in the political process.}
}
@article{bebensee2021leveraging,
	title        = {{Leveraging node neighborhoods and egograph topology for better bot detection in social graphs}},
	author       = {{Bebensee, Bj\"o}rn and Nazarov, Nagmat and Zhang, Byoung-Tak}},
	year         = 2021,
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer},
	volume       = 11,
	number       = 1,
	pages        = {1--14},
	doi          = {https://doi.org/10.1007/s13278-020-00713-z}
}
@article{becker2017network,
	title        = {{Network dynamics of social influence in the wisdom of crowds}},
	author       = {{Becker, Joshua and Brackbill, Devon and Centola, Damon}},
	year         = 2017,
	journal      = {Proceedings of the national academy of sciences},
	publisher    = {National Acad Sciences},
	volume       = 114,
	number       = 26,
	pages        = {E5070--E5076}
}
@article{Ben-Yashar2000,
	title        = {{A nonasymptotic Condorcet jury theorem}},
	author       = {{Ben-Yashar, Ruth and Paroush, Jacob}},
	year         = 2000,
	journal      = {Social Choice and Welfare},
	volume       = 17,
	number       = 2,
	pages        = {189--199}
}
@article{Berend2005,
	title        = {{Monotonicity in Condorcet Jury Theorem}},
	author       = {{Berend, Daniel and Sapir, Luba}},
	year         = 2005,
	journal      = {Social Choice and Welfare},
	volume       = 24,
	number       = 1,
	pages        = {83--92}
}
@article{Berend2007,
	title        = {{Monotonicity in Condorcet's Jury Theorem with dependent voters}},
	author       = {{Berend, Daniel and Sapir, Luba}},
	year         = 2007,
	journal      = {Social Choice and Welfare},
	volume       = 28,
	number       = 3,
	pages        = {507--528}
}
@article{Berger2012,
	title        = {{What Makes Online Content Viral?}},
	author       = {{Berger, Jonah and Milkman, Katherine L.}},
	year         = 2012,
	journal      = {Journal of Marketing Research},
	volume       = 49,
	number       = 2,
	pages        = {192--205}
}
@inproceedings{beutel2013copycatch,
	title        = {{Copycatch: Stopping group attacks by spotting lockstep behavior in social networks}},
	author       = {{Beutel, Alex and Xu, Wanhong and Guruswami, Venkatesan and Palow, Christopher and Faloutsos, Christos}},
	year         = 2013,
	booktitle    = {Proceedings of the 22nd international conference on World Wide Web},
	pages        = {119--130},
	doi          = {https://doi.org/10.1145/2488388.2488400}
}
@article{Bhadani2022_Nature_diversity,
	title        = {{Political audience diversity and news reliability in algorithmic ranking}},
	author       = {{Bhadani, Saumya and Yamaya, Shun and Flammini, Alessandro and Menczer, Filippo and Ciampaglia, Giovanni Luca and Nyhan, Brendan}},
	year         = 2022,
	journal      = {Nature Human Behaviour},
	doi          = {https://doi.org/10.1038/s41562-021-01276-5},
	isbn         = {2397-3374},
	id           = {Bhadani2022},
	ty           = {JOUR}
}
@article{Bicchieri1999,
	title        = {{The great illusion: ignorance, informational cascades, and the persistence of unpopular norms}},
	author       = {{Bicchieri, Cristina and Fukui, Yoshitaka}},
	year         = 1999,
	journal      = {Business Ethics Quarterly},
	volume       = 9,
	number       = 1,
	pages        = {127--155}
}
@article{Bikhchandani1992,
	title        = {{A Theory of Fads, Fashion, Custom, and Cultural Change as Informational Cascades}},
	author       = {{Bikhchandani, Sushil and Hirshleifer, David and Welch, Ivo}},
	year         = 1992,
	month        = {jan},
	journal      = {Journal of Political Economy},
	volume       = 100,
	number       = 5,
	pages        = {992--1026},
	issn         = {0022-3808}
}
@misc{Botometer,
	title        = {{Bot Repository}},
	note         = {Accessed: 2022-01-15},
	howpublished = {\url{https://botometer.osome.iu.edu/bot-repository/datasets.html}}
}
@article{Bradshaw2017,
	title        = {{Troops, Trolls and Troublemakers: A Global Inventory of Organized Social Media Manipulation}},
	author       = {{Bradshaw, Samantha and Howard, Philipp N.}},
	year         = 2017,
	journal      = {Computational Propaganda Research Project},
	volume       = 2017,
	number       = 12,
	pages        = {1--37}
}
@article{Brake2014,
	title        = {{Are We All Online Content Creators Now? Web 2.0 and Digital Divides*}},
	author       = {{Brake, David R.}},
	year         = 2014,
	journal      = {Journal of Computer-Mediated Communication},
	volume       = 19,
	number       = 3,
	pages        = {591--609}
}
@article{brashier2020initialaccuracy,
	title        = {{An initial accuracy focus prevents illusory truth}},
	author       = {{Brashier, Nadia M and Eliseev, Emmaline Drew and Marsh, Elizabeth J}},
	year         = 2020,
	journal      = {Cognition},
	publisher    = {Elsevier},
	volume       = 194,
	pages        = 104054
}
@article{calo2021you,
	title        = {{How do you solve a problem like misinformation?}},
	author       = {{Calo, Ryan and Coward, Chris and Spiro, Emma S and Starbird, Kate and West, Jevin D}},
	year         = 2021,
	journal      = {Science advances},
	publisher    = {American Association for the Advancement of Science},
	volume       = 7,
	number       = 50,
	pages        = {eabn0481}
}
@article{Cantini2022,
	title        = {{Analyzing Political Polarization on Social Media by Deleting Bot Spamming}},
	author       = {{Riccardo Cantini and Fabrizio Marozzo and Domenico Talia and Paolo Trunfio}},
	year         = 2022,
	month        = 3,
	journal      = {Big Data and Cognitive Computing},
	publisher    = {MDPI},
	volume       = 6,
	doi          = {10.3390/bdcc6010003},
	issn         = 25042289,
	issue        = 1,
	keywords     = {Influence spread,Political polarization,Social bots,Social media analysis},
	abstract     = {Social media platforms are part of everyday life, allowing the interconnection of people around the world in large discussion groups relating to every topic, including important social or political issues. Therefore, social media have become a valuable source of information-rich data, commonly referred to as Social Big Data, effectively exploitable to study the behavior of people, their opinions, moods, interests and activities. However, these powerful communication platforms can be also used to manipulate conversation, polluting online content and altering the popularity of users, through spamming activities and misinformation spreading. Recent studies have shown the use on social media of automatic entities, defined as social bots, that appear as legitimate users by imitating human behavior aimed at influencing discussions of any kind, including political issues. In this paper we present a new methodology, namely TIMBRE (Time-aware opInion Mining via Bot REmoval), aimed at discovering the polarity of social media users during election campaigns characterized by the rivalry of political factions. This methodology is temporally aware and relies on a keyword-based classification of posts and users. Moreover, it recognizes and filters out data produced by social media bots, which aim to alter public opinion about political candidates, thus avoiding heavily biased information. The proposed methodology has been applied to a case study that analyzes the polarization of a large number of Twitter users during the 2016 US presidential election. The achieved results show the benefits brought by both removing bots and taking into account temporal aspects in the forecasting process, revealing the high accuracy and effectiveness of the proposed approach. Finally, we investigated how the presence of social bots may affect political discussion by studying the 2016 US presidential election. Specifically, we analyzed the main differences between human and artificial political support, estimating also the influence of social bots on legitimate users.}
}
@misc{CarniegeIndexInterventions,
	title        = {{Platform Interventions: How Social Media Counters Influence Operations}},
	author       = {{Kamya Yadav}},
	publisher    = {{Carniege Endowment for International Peace}},
	note         = {Accessed: 2022-12-06},
	howpublished = {\url{https://carnegieendowment.org/2021/01/25/platform-interventions-how-social-media-counters-influence-operations-pub-83698}}
}
@article{ccitlak2019survey,
	title        = {{A survey on detecting spam accounts on Twitter network}},
	author       = {{\c{C}\i}tlak, O{\u{g}}uzhan and D{\"o}rterler, Murat and Do{\u{g}}ru, {\.I}brahim Alper},
	year         = {2019},
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer},
	volume       = 9,
	number       = 1,
	pages        = {1--13}
}
@article{centola2007complex,
	title        = {{Complex contagions and the weakness of long ties}},
	author       = {{Centola, Damon and Macy, Michael}},
	year         = 2007,
	journal      = {American journal of Sociology},
	publisher    = {The University of Chicago Press},
	volume       = 113,
	number       = 3,
	pages        = {702--734}
}
@article{Chandler2014,
	title        = {{Nonna\"{i}vet\'{e} among Amazon Mechanical Turk workers: Consequences and solutions for behavioral researchers}},
	author       = {{Chandler, Jesse and Mueller, Pam and Paolacci, Gabriele}},
	year         = 2014,
	journal      = {Behavior Research Methods},
	volume       = 46,
	number       = 1,
	pages        = {112--130},
	doi          = {10.3758/s13428-013-0365-7},
	issn         = 15543528,
	abstract     = {Crowdsourcing services-particularly Amazon Mechanical Turk-have made it easy for behavioral scientists to recruit research participants. However, researchers have overlooked crucial differences between crowdsourcing and traditional recruitment methods that provide unique opportunities and challenges. We show that crowdsourced workers are likely to participate across multiple related experiments and that researchers are overzealous in the exclusion of research participants. We describe how both of these problems can be avoided using advanced interface features that also allow prescreening and longitudinal data collection. Using these techniques can minimize the effects of previously ignored drawbacks and expand the scope of crowdsourcing as a tool for psychological research. {\textcopyright} 2013 Psychonomic Society, Inc.},
	keywords     = {Crowdsourcing,Data quality,Internet research,Longitudinal research,MTurk,Mechanical Turk},
	pmid         = 23835650
}
@article{Chavoshi2017_unsupervised,
	title        = {{DeBot: Twitter bot detection via warped correlation}},
	author       = {{Chavoshi, Nikan and Hamooni, Hossein and Mueen, Abdullah}},
	year         = 2017,
	journal      = {Proceedings - IEEE International Conference on Data Mining, ICDM},
	pages        = {817--822},
	doi          = {http://dx.doi.org/10.1109/ICDM.2016.0096}
}
@article{Chen_Unsupervised,
	title        = {{An Unsupervised Approach to Detect Spam Campaigns that Use Botnets on Twitter}},
	author       = {{Chen, Zhouhan and Subramanian, Devika}},
	year         = 2018,
	journal      = {arXiv},
	doi          = {https://doi.org/10.48550/arXiv.1804.05232}
}
@article{Chen2021,
	title        = {{Neutral bots probe political bias on social media}},
	author       = {{Wen Chen and Diogo Pacheco and Kai Cheng Yang and Filippo Menczer}},
	year         = 2021,
	month        = 12,
	journal      = {Nature Communications},
	publisher    = {Nature Research},
	volume       = 12,
	doi          = {10.1038/s41467-021-25738-6},
	issn         = 20411723,
	issue        = 1,
	pmid         = 34552073,
	abstract     = {Social media platforms attempting to curb abuse and misinformation have been accused of political bias. We deploy neutral social bots who start following different news sources on Twitter, and track them to probe distinct biases emerging from platform mechanisms versus user interactions. We find no strong or consistent evidence of political bias in the news feed. Despite this, the news and information to which U.S. Twitter users are exposed depend strongly on the political leaning of their early connections. The interactions of conservative accounts are skewed toward the right, whereas liberal accounts are exposed to moderate content shifting their experience toward the political center. Partisan accounts, especially conservative ones, tend to receive more followers and follow more automated accounts. Conservative accounts also find themselves in denser communities and are exposed to more low-credibility content.}
}
@article{Chierichetti2014,
	title        = {{How to Schedule a Cascade in an Arbitrary Graph}},
	author       = {{Chierichetti, F. and Kleinberg, J. and Panconesi, A.}},
	year         = 2014,
	journal      = {SIAM Journal on Computing},
	volume       = 43,
	number       = 6,
	pages        = {1906--1920}
}
@article{Chumber2015,
	title        = {{A Methodology to Analyze the Quality of Health Information on the Internet: The Example of Diabetic Neuropathy}},
	author       = {{Sundeep Chumber and J\"o}g Huber and Pietro Ghezzi}},
	year         = 2015,
	journal      = {The Diabetes Educator},
	volume       = 41,
	number       = 1,
	pages        = {95--105}
}
@article{ciampaglia2015attentionecon,
	title        = {{The production of information in the attention economy}},
	author       = {{Ciampaglia, Giovanni Luca and Flammini, Alessandro and Menczer, Filippo}},
	year         = 2015,
	journal      = {Scientific reports},
	publisher    = {Nature Publishing Group},
	volume       = 5,
	number       = 1,
	pages        = {1--6}
}
@article{ciampaglia2018algorithmic,
	title        = {{How algorithmic popularity bias hinders or promotes quality}},
	author       = {{Ciampaglia, Giovanni Luca and Nematzadeh, Azadeh and Menczer, Filippo and Flammini, Alessandro}},
	year         = 2018,
	journal      = {Scientific reports},
	publisher    = {Nature Publishing Group},
	volume       = 8,
	number       = 1,
	pages        = {1--7}
}
@book{Condorcet,
	title        = {{Essai sur l'Application de l'Analyse \`{a} la Probabilit\'{e} des D\'{e}cisions Rendues \`{a} la Pluralit\'{e} des Voix}},
	author       = {{Condorcet , M.J.A.N.C. Marquis de}},
	year         = 1785,
	publisher    = {Paris}
}
@techreport{CRA-agenda-2020,
	title        = {{An Agenda for Disinformation Research}},
	author       = {{Nadya Bliss and Elizabeth Bradley and Joshua Garland and Filippo Menczer and Scott Ruston and Kate Starbird and Chris Wiggins}},
	year         = 2020,
	number       = {arXiv:2012.08572},
	url          = {https://arxiv.org/abs/2012.08572},
	date-added   = {2021-01-07 04:00:22 -0500},
	date-modified = {2021-01-07 04:04:53 -0500},
	institution  = {CRA Computing Community Consortium (CCC)},
	keywords     = {myown abuse osome social},
	type         = {Quadrennial Paper},
	bdsk-url-1   = {https://arxiv.org/abs/2012.08572}
}
@article{Cresci2016,
	title        = {{DNA-Inspired Online Behavioral Modeling and Its Application to Spambot Detection}},
	author       = {{Stefano Cresci and Roberto Di Pietro and Marinella Petrocchi and Angelo Spognardi and Maurizio Tesconi}},
	year         = 2016,
	month        = 9,
	journal      = {IEEE Intelligent Systems},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = 31,
	pages        = {58--64},
	doi          = {10.1109/MIS.2016.29},
	issn         = 15411672,
	issue        = 5,
	keywords     = {data mining,intelligent systems,knowledge representation formalisms and methods,social science methods or tools},
	abstract     = {A novel, simple, and effective approach to modeling online user behavior extracts and analyzes digital DNA sequences from user online actions and uses Twitter as a benchmark to test the proposal. Specifically, the model obtains an incisive and compact DNA-inspired characterization of user actions. Then, standard DNA analysis techniques discriminate between genuine and spambot accounts on Twitter. An experimental campaign supports the proposal, showing its effectiveness and viability. Although Twitter spambot detection is a specific use case on a specific social media platform, the proposed methodology is platform and technology agnostic, paving the way for diverse behavioral characterization tasks.}
}
@inproceedings{cresci2017paradigm,
	title        = {{The paradigm-shift of social spambots: Evidence, theories, and tools for the arms race}},
	author       = {{Cresci, Stefano and Di Pietro, Roberto and Petrocchi, Marinella and Spognardi, Angelo and Tesconi, Maurizio}},
	year         = 2017,
	booktitle    = {Proceedings of the 26th international conference on world wide web companion},
	pages        = {963--972},
	doi          = {https://doi.org/10.1145/3041021.3055135}
}
@article{Cresci2018,
	title        = {{Social Fingerprinting: Detection of Spambot Groups Through DNA-Inspired Behavioral Modeling}},
	author       = {{Stefano Cresci and Roberto Di Pietro and Marinella Petrocchi and Angelo Spognardi and Maurizio Tesconi}},
	year         = 2018,
	month        = 7,
	journal      = {IEEE Transactions on Dependable and Secure Computing},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = 15,
	pages        = {561--576},
	doi          = {10.1109/TDSC.2017.2681672},
	issn         = 19410018,
	url          = {www.aaai.org},
	issue        = 4,
	keywords     = {Spambot detection,Twitter,behavioral modeling,digital DNA,online social networks,social bots},
	abstract     = {Spambot detection in online social networks is a long-lasting challenge involving the study and design of detection techniques capable of efficiently identifying ever-evolving spammers. Recently, a new wave of social spambots has emerged, with advanced human-like characteristics that allow them to go undetected even by current state-of-the-art algorithms. In this paper, we show that efficient spambots detection can be achieved via an in-depth analysis of their collective behaviors exploiting the digital DNA technique for modeling the behaviors of social network users. Inspired by its biological counterpart, in the digital DNA representation the behavioral lifetime of a digital account is encoded in a sequence of characters. Then, we define a similarity measure for such digital DNA sequences. We build upon digital DNA and the similarity between groups of users to characterize both genuine accounts and spambots. Leveraging such a characterization, we design the Social Fingerprinting technique, which is able to discriminate among spambots and genuine accounts in both a supervised and an unsupervised fashion. We also evaluate the effectiveness of Social Fingerprinting and we compare it with three state-of-the-art detection showing the superiority of our solution. Finally, among the peculiarities of our approach is the possibility to apply off-the-shelf DNA analysis techniques to study online users behaviors and to efficiently rely on a limited number of lightweight account characteristics.}
}
@report{Cresci2018b,
	title        = {{$FAKE: Evidence of Spam and Bot Activity in Stock Microblogs on Twitter}},
	author       = {{Stefano Cresci and Fabrizio Lillo and Daniele Regoli and Serena Tardelli and Maurizio Tesconi}},
	year         = 2018,
	keywords     = {Full Papers}
}
@article{Cresci2019,
	title        = {{Cashtag piggybacking: Uncovering spam and bot activity in stock microblogs on twitter}},
	author       = {{Stefano Cresci and Fabrizio Lillo and Daniele Regoli and Serena Tardelli and Maurizio Tesconi}},
	year         = 2019,
	month        = 4,
	journal      = {ACM Transactions on the Web},
	publisher    = {Association for Computing Machinery},
	volume       = 13,
	doi          = {10.1145/3313184},
	issn         = {1559114X},
	issue        = 2,
	keywords     = {Social networks security,Social spam,Spam and bot detection,Stock market,Twitter},
	abstract     = {Microblogs are increasingly exploited for predicting prices and traded volumes of stocks in financial markets. However, it has been demonstrated that much of the content shared in microblogging platforms is created and publicized by bots and spammers. Yet, the presence (or lack thereof) and the impact of fake stock microblogs has never been systematically investigated before. Here, we study 9M tweets related to stocks of the five main financial markets in the US. By comparing tweets with financial data from Google Finance, we highlight important characteristics of Twitter stock microblogs. More importantly, we uncover a malicious practice-referred to as cashtag piggybacking-perpetrated by coordinated groups of bots and likely aimed at promoting low-value stocks by exploiting the popularity of high-value ones. Among the findings of our study is that as much as 71% of the authors of suspicious financial tweets are classified as bots by a state-of-the-art spambot-detection algorithm. Furthermore, 37% of them were suspended by Twitter a few months after our investigation. Our results call for the adoption of spam- and bot-detection techniques in all studies and applications that exploit user-generated content for predicting the stock market.}
}
@inproceedings{Cristofaro2014_fblikes,
	title        = {{Paying for likes? Understanding Facebook Like Fraud Using Honeypots}},
	author       = {{De Cristofaro, Emiliano and Friedman, Arik and Jourjon, Guillaume and Kaafar, Mohamed Ali and Shafiq, M Zubair}},
	year         = 2014,
	booktitle    = {Proceedings of the 2014 Conference on Internet Measurement Conference},
	pages        = {129--136},
	doi          = {http://dx.doi.org/10.1145/2663716.2663729}
}
@book{crowdsourcing,
	title        = {{Getting Results From Crowds}},
	author       = {{Dawson, Ross and Bynghall, Steve}},
	year         = 2011,
	publisher    = {Advanced Human Technologies Inc}
}
@misc{Dataverse,
	title        = {{Code and Dataset on Harvard Dataverse}},
	author       = {{Anonymous Blinded}},
	year         = 2022,
	note         = {Blinded for review},
	howpublished = {\url{https://dataverse.harvard.edu/privateurl.xhtml?token=8b1653e5-eb96-4d90-a3e0-df871daf258c}}
}
@misc{Decahose,
	title        = {{Decahose API}},
	note         = {Accessed: 2022-09-10},
	howpublished = {\url{https://developer.twitter.com/en/docs/twitter-api/enterprise/decahose-api/overview/streaming-likes}}
}
@article{DeFreitasMelo2020,
	title        = {{Can WhatsApp Counter Misinformation by Limiting Message Forwarding?}},
	author       = {{de Freitas Melo, Philipe and Vieira, Carolina Coimbra and Garimella, Kiran and de Melo, Pedro O.S.Vaz and Benevenuto, Fabr\'i}­Cio}},
	year         = 2020,
	journal      = {Studies in Computational Intelligence},
	volume       = {881 SCI},
	pages        = {372--384},
	doi          = {10.1007/978-3-030-36687-2_31},
	isbn         = 9783030366865,
	issn         = 18609503,
	abstract     = {WhatsApp is the most popular messaging app in the world. The closed nature of the app, in addition to the ease of transferring multimedia and sharing information to large-scale groups make WhatsApp unique among other platforms, where an anonymous encrypted messages can become viral, reaching multiple users in a short period of time. The personal feeling and immediacy of messages directly delivered to the user's phone on WhatsApp was extensively abused to spread unfounded rumors and create misinformation campaigns during recent elections in Brazil and India. WhatsApp has been deploying measures to mitigate this problem, such as reducing the limit for forwarding a message to at most five users at once. Despite the welcomed effort to counter the problem, there is no evidence so far on the real effectiveness of such restrictions. In this work, we propose a methodology to evaluate the effectiveness of such measures on the spreading of misinformation circulating on WhatsApp. We use an epidemiological model and real data gathered from WhatsApp in Brazil, India and Indonesia to assess the impact of limiting virality features in this kind of network. Our results suggest that the current efforts deployed by WhatsApp can offer delays on the information spread, but are ineffective in blocking the propagation of misinformation campaigns in public groups.},
	archiveprefix = {arXiv},
	arxivid      = {1909.08740},
	eprint       = {1909.08740},
	keywords     = {Complex network,Epidemiological model,Fake news,Misinformation,Virality,WhatsApp}
}
@article{Derhab2021,
	title        = {{Tweet-Based Bot Detection Using Big Data Analytics}},
	author       = {{Derhab, Abdelouahid and Alawwad, Rahaf and Dehwah, Khawlah and Tariq, Noshina and Khan, Farrukh Aslam and Al-Muhtadi, Jalal}},
	year         = 2021,
	journal      = {IEEE Access},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = 9,
	pages        = {65988--66005},
	doi          = {10.1109/ACCESS.2021.3074953},
	issn         = 21693536,
	abstract     = {Twitter is one of the most popular micro-blogging social media platforms that has millions of users. Due to its popularity, Twitter has been targeted by different attacks such as spreading rumors, phishing links, and malware. Tweet-based botnets represent a serious threat to users as they can launch large-scale attacks and manipulation campaigns. To deal with these threats, big data analytics techniques, particularly shallow and deep learning techniques have been leveraged in order to accurately distinguish between human accounts and tweet-based bot accounts. In this paper, we discuss existing techniques, and provide a taxonomy that classifies the state-of-the-art of tweet-based bot detection techniques. We also describe the shallow and deep learning techniques for tweet-based bot detection, along with their performance results. Finally, we present and discuss the challenges and open issues in the area of tweet-based bot detection.},
	keywords     = {Social media,Twitter,big data analytics,deep learning,shallow learning,tweet-based bot detection}
}
@article{Dietrich2013,
	title        = {{Epistemic Democracy with Defensible Premises}},
	author       = {{Dietrich, Franz and Spiekermann, Kai}},
	year         = 2013,
	journal      = {Economics and Philosophy},
	volume       = 29,
	number       = 1,
	pages        = {87--120}
}
@inproceedings{DietrichtSpiekermann,
	title        = {{Jury Theorems}},
	author       = {{Franz Dietricht and Kai Spiekermann}},
	year         = 2019,
	booktitle    = {The Routledge Companion to Social Epistemology},
	publisher    = {Routledge},
	editor       = {Miranda Fricker and Peter~J. Graham and David Henderson and Nikolaj Pedersen and Jeremy Wyatt}
}
@article{Dimitrov2020Covid19tweets,
	title        = {{TweetsCOV19 - A Knowledge Base of Semantically Annotated Tweets about the COVID-19 Pandemic}},
	author       = {{Dimitrov, Dimitar and Baran, Erdal and Fafalios, Pavlos and Yu, Ran and Zhu, Xiaofei and Zloch, Matth\"{a}us and Dietze, Stefan}},
	year         = 2020,
	journal      = {International Conference on Information and Knowledge Management, Proceedings},
	number       = {June},
	pages        = {2991--2998},
	doi          = {10.1145/3340531.3412765},
	isbn         = 9781450368599,
	abstract     = {Publicly available social media archives facilitate research in the social sciences and provide corpora for training and testing a wide range of machine learning and natural language processing methods. With respect to the recent outbreak of the Coronavirus disease 2019 (COVID-19), online discourse on Twitter reflects public opinion and perception related to the pandemic itself as well as mitigating measures and their societal impact. Understanding such discourse, its evolution, and interdependencies with real-world events or (mis)information can foster valuable insights. On the other hand, such corpora are crucial facilitators for computational methods addressing tasks such as sentiment analysis, event detection, or entity recognition. However, obtaining, archiving, and semantically annotating large amounts of tweets is costly. In this paper, we describe TweetsCOV19, a publicly available knowledge base of currently more than 8 million tweets, spanning October 2019 - April 2020. Metadata about the tweets as well as extracted entities, hashtags, user mentions, sentiments, and URLs are exposed using established RDF/S vocabularies, providing an unprecedented knowledge base for a range of knowledge discovery tasks. Next to a description of the dataset and its extraction and annotation process, we present an initial analysis and use cases of the corpus.},
	archiveprefix = {arXiv},
	arxivid      = {2006.14492},
	eprint       = {2006.14492},
	file         = {:Users/qbj218/Dropbox/Laura/Friction Strategies/Lit/Academic/2020{\_}Covid twitter dataset.pdf:pdf},
	keywords     = {coronavirus,covid-19,entity linking,rdf,sentiment analysis,social media archives,twitter}
}
@techreport{Disinfresearch-agenda-2020,
	title        = {{An Agenda for Disinformation Research}},
	author       = {{Nadya Bliss and Elizabeth Bradley and Joshua Garland and Filippo Menczer and Scott Ruston and Kate Starbird and Chris Wiggins}},
	year         = 2020,
	date-added   = {2021-01-07 04:00:22 -0500},
	date-modified = {2021-01-07 04:04:53 -0500},
	institution  = {CRA Computing Community Consortium (CCC)},
	type         = {Quadrennial Paper}
}
@misc{DSA,
	title        = {{The Digital Services Act: ensuring a safe and accountable online environment}},
	author       = {{The European Union}},
	note         = {Accessed: 2022-12-22},
	howpublished = {\url{https://commission.europa.eu/strategy-and-policy/priorities-2019-2024/europe-fit-digital-age/digital-services-act-ensuring-safe-and-accountable-online-environment_en}}
}
@article{duan2022botsIndiana,
	title        = {{Algorithmic Agents in the Hybrid Media System: Social Bots, Selective Amplification, and Partisan News about COVID-19}},
	author       = {{Duan, Zening and Li, Jianing and Lukito, Josephine and Yang, Kai-Cheng and Chen, Fan and Shah, Dhavan V and Yang, Sijia}},
	year         = 2022,
	journal      = {Human Communication Research}
}
@inproceedings{dutta2018retweet,
	title        = {{Retweet us, we will retweet you: Spotting collusive retweeters involved in blackmarket services}},
	author       = {{Dutta, Hridoy Sankar and Chetan, Aditya and Joshi, Brihi and Chakraborty, Tanmoy}},
	year         = 2018,
	booktitle    = {2018 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)},
	pages        = {242--249},
	organization = {IEEE}
}
@book{Endriss2017,
	title        = {{Trends in Computational Social Choice}},
	year         = 2017,
	publisher    = {AI Access},
	pages        = 402,
	editor       = {Endriss, Ulle}
}
@article{epidemics2,
	title        = {{The spread of epidemic disease on networks}},
	author       = {{Newman, M. E. J.}},
	year         = 2002,
	journal      = {Physical Review E},
	volume       = 66,
	number       = 1,
	pages        = {016128}
}
@article{epstein2022many,
	title        = {{How many others have shared this? Experimentally investigating the effects of social cues on engagement, misinformation, and unpredictability on social media}},
	author       = {{Epstein, Ziv and Lin, Hause and Pennycook, Gordon and Rand, David}},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2207.07562}
}
@article{epstein2022sharingexperiment,
	title        = {{How many others have shared this? Experimentally investigating the effects of social cues on engagement, misinformation, and unpredictability on social media}},
	author       = {{Epstein, Ziv and Lin, Hause and Pennycook, Gordon and Rand, David}},
	year         = 2022,
	journal      = {arXiv preprint arXiv:2207.07562}
}
@article{Fakey2021,
	title        = {{Fakey: A Game Intervention to Improve News Literacy on Social Media}},
	author       = {{Nicholas Micallef and Mihai Avram and Filippo Menczer and Sameer Patil}},
	year         = 2021,
	journal      = {Proc. ACM Human-Computer Interaction},
	volume       = 5,
	number       = {CSCW1},
	pages        = 6,
	doi          = {10.1145/3449080},
	url          = {https://doi.org/10.1145/3449080}
}
@article{fazio2015illusionaryeffect,
	title        = {{Knowledge does not protect against illusory truth.}},
	author       = {{Fazio, Lisa K and Brashier, Nadia M and Payne, B Keith and Marsh, Elizabeth J}},
	year         = 2015,
	journal      = {Journal of Experimental Psychology: General},
	publisher    = {American Psychological Association},
	volume       = 144,
	number       = 5,
	pages        = 993
}
@article{Fazio2020,
	title        = {{Pausing to consider why a headline is true or false can help reduce the sharing of false news}},
	author       = {{Fazio, Lisa}},
	year         = 2020,
	journal      = {Harvard Kennedy School Misinformation Review},
	volume       = 1,
	number       = 2,
	pages        = {1--8},
	doi          = {10.37016/mr-2020-009},
	abstract     = {In an online experiment, participants who paused to explain why a headline was true or false indicated that they were less likely to share false information compared to control participants. Their intention to share accurate news stories was unchanged. These results indicate that adding “friction” (i.e., pausing to think) before sharing can improve the quality of information shared on social media.}
}
@inproceedings{Feng_Twi-Bot_2021,
	title        = {{TwiBot-20: A Comprehensive Twitter Bot Detection Benchmark}},
	author       = {{Feng, Shangbin and Wan, Herun and Wang, Ningnan and Li, Jundong and Luo, Minnan and Luo, Minnan}},
	year         = 2021,
	booktitle    = {Proceedings of the 30th ACM International Conference on Information & Knowledge Management},
	location     = {Virtual Event, Queensland, Australia},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {CIKM '21},
	pages        = {4485–4494},
	isbn         = 9781450384469,
	numpages     = 10
}
@article{Feng2021,
	title        = {{Heterogeneity-aware Twitter Bot Detection with Relational Graph Transformers}},
	author       = {{Shangbin Feng and Zhaoxuan Tan and Rui Li and Minnan Luo}},
	year         = 2021,
	month        = 9,
	journal      = {International Conference on Information and Knowledge Management, Proceedings},
	publisher    = {Association for Computing Machinery},
	pages        = {4485--4494},
	doi          = {10.1145/3459637.3482019},
	isbn         = 9781450384469,
	url          = {http://arxiv.org/abs/2109.02927},
	abstract     = {Twitter bot detection has become an important and challenging task to combat misinformation and protect the integrity of the online discourse. State-of-the-art approaches generally leverage the topological structure of the Twittersphere, while they neglect the heterogeneity of relations and influence among users. In this paper, we propose a novel bot detection framework to alleviate this problem, which leverages the topological structure of user-formed heterogeneous graphs and models varying influence intensity between users. Specifically, we construct a heterogeneous information network with users as nodes and diversified relations as edges. We then propose relational graph transformers to model heterogeneous influence between users and learn node representations. Finally, we use semantic attention networks to aggregate messages across users and relations and conduct heterogeneity-aware Twitter bot detection. Extensive experiments demonstrate that our proposal outperforms state-of-the-art methods on a comprehensive Twitter bot detection benchmark. Additional studies also bear out the effectiveness of our proposed relational graph transformers, semantic attention networks and the graph-based approach in general.},
	keywords     = {benchmarking,social media,twitter API,twitter bot detection}
}
@article{Ferrara:2016,
	title        = {{The Rise of Social Bots}},
	author       = {{Ferrara, Emilio and Varol, Onur and Davis, Clayton and Menczer, Filippo and Flammini, Alessandro}},
	year         = 2016,
	journal      = {Commun. ACM},
	publisher    = {ACM},
	volume       = 59,
	number       = 7,
	pages        = {96--104}
}
@article{Ferrara2017,
	title        = {{Disinformation and social bot operations in the run up to the 2017 French presidential election}},
	author       = {{Emilio Ferrara}},
	year         = 2017,
	journal      = {First Monday},
	volume       = 22,
	number       = 8,
	doi          = {10.5210/fm.v22i8.8005},
	issn         = 13960466,
	url          = {https://firstmonday.org/ojs/index.php/fm/article/view/8005}
}
@inproceedings{FrankeGaleazzi14,
	title        = {{On the Evolution of Choice Principles}},
	author       = {{Michael Franke and Paolo Galeazzi}},
	year         = 2014,
	booktitle    = {Proceedings of the Second Workshop on Reasoning About Other Minds},
	publisher    = {CEUR},
	series       = {CEUR Workshop Proceedings},
	volume       = 1208,
	pages        = {11--15}
}
@article{freitas2016empirical,
	title        = {{An empirical study of socialbot infiltration strategies in the Twitter social network}},
	author       = {{Freitas, Carlos and Benevenuto, Fabr\'\i}cio and Veloso, Adriano and Ghosh, Saptarshi}},
	year         = 2016,
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer},
	volume       = 6,
	number       = 1,
	pages        = {1--16}
}
@article{friendly2002corrgrams,
	title        = {{Corrgrams: Exploratory displays for correlation matrices}},
	author       = {{Friendly, Michael}},
	year         = 2002,
	journal      = {The American Statistician},
	publisher    = {Taylor \& Francis},
	volume       = 56,
	number       = 4,
	pages        = {316--324}
}
@article{froese2020comparing,
	title        = {{Comparing temporal graphs using dynamic time warping}},
	author       = {{Froese, Vincent and Jain, Brijnesh and Niedermeier, Rolf and Renken, Malte}},
	year         = 2020,
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer},
	volume       = 10,
	number       = 1,
	pages        = {1--16}
}
@article{Gagliardi2002,
	title        = {{Examination of instruments used to rate quality of health information on the internet: chronicle of a voyage with an unclear destination}},
	author       = {{Gagliardi, Anna and Jadad, Alejandro~R.}},
	year         = 2002,
	journal      = {BMJ},
	publisher    = {BMJ Publishing Group Ltd},
	volume       = 324,
	number       = 7337,
	pages        = {569--573}
}
@inproceedings{GaleazziRendsvigSlavkovik2019,
	title        = {{Improving Judgment Reliability in Social Networks via Jury Theorems}},
	author       = {{Paolo Galeazzi and Rasmus~K. Rendsvig and Marija Slavkovik}},
	year         = 2019,
	booktitle    = {{Logic, Rationality, and Interaction (LORI 2019)}},
	publisher    = {Springer},
	series       = {{Lecture Notes in Computer Science}},
	volume       = 11813,
	pages        = {230--243},
	editorrr     = {Blackburn, Patrick and Lorini, Emiliano and Guo, Meiyun},
	editor       = {Blackburn, Patrick and Lorini, Emiliano and Guo, Meiyun},
	doiii        = {https://doi.org/10.1007/978-3-662-60292-8_17}
}
@inproceedings{GaleazziTer17,
	title        = {{Relief Maximization and Rationality}},
	author       = {{Paolo Galeazzi and Zoi Terzopoulou}},
	year         = 2017,
	booktitle    = {{LORI}},
	publisher    = {Springer},
	series       = {Lecture Notes in Computer Science},
	volume       = 10455,
	pages        = {670--675}
}
@article{GalFra17,
	title        = {{Smart Representations: Rationality and Evolution in a Richer Environment}},
	author       = {{Galeazzi, Paolo and Franke, Michael}},
	year         = 2017,
	journal      = {Philosophy of Science},
	volume       = 84,
	number       = 3,
	pages        = {544--573}
}
@article{Galton1907,
	title        = {{Vox Populi}},
	author       = {{Galton, Francis}},
	year         = 1907,
	journal      = {Nature},
	volume       = 75,
	pages        = {450--451}
}
@book{Game3,
	title        = {{Networks, Crowds, and Markets: Reasoning about a Highly Connected World}},
	author       = {{Easley, David and Kleinberg, Jon}},
	year         = 2010,
	publisher    = {Cambridge University Press}
}
@article{Giglietto2020coordinated,
	title        = {{It takes a village to manipulate the media: coordinated link sharing behavior during 2018 and 2019 Italian elections}},
	author       = {{Giglietto, Fabio and Righetti, Nicola and Rossi, Luca and Marino, Giada}},
	year         = 2020,
	journal      = {Information Communication and Society},
	publisher    = {Taylor {\&} Francis},
	volume       = 23,
	number       = 6,
	pages        = {867--891},
	doi          = {https://doi.org/10.1080/1369118X.2020.1739732},
	issn         = 14684462
}
@article{Giglietto2020coordinated2,
	title        = {{Coordinated Link Sharing Behavior as a Signal to Surface Sources of Problematic Information on Facebook}},
	author       = {{Giglietto, Fabio and Righetti, Nicola and Rossi, Luca and Marino, Giada}},
	year         = 2020,
	journal      = {ACM International Conference Proceeding Series},
	pages        = {85--91},
	doi          = {https://doi.org/10.1145/3400806.3400817},
	isbn         = 9781450376884,
	abstract     = {Despite widespread concern over the role played by disinformation during recent electoral processes, the intrinsic elusiveness of the subject hinders efforts aimed at estimating its prevalence and effect. While there has been proliferation of attempts to define, understand and fight the spread of problematic information in contemporary media ecosystems, most of these attempts focus on detecting false content and/or bad actors. For instance, several existing studies rely on lists of problematic content or news media sources compiled by fact-checkers. However, these lists may quickly become obsolete leading to unreliable estimates. Using media manipulation as a frame, along with a revised version of the "coordinated inauthentic behavior" original definition, in this paper, we argue for a wider ecological focus. Leveraging a method designed to detect "coordinated links sharing behavior" (CLSB), we introduce and assess an approach aimed at creating and keeping lists of potentially problematic sources updated by analyzing the URLs shared on Facebook by public groups, pages, and verified profiles. We show how CLSB is consistently associated with higher risks of encountering problematic news sources across three different datasets of news stories and can be thus used as a signal to support manual and automatic detection of problematic information.},
	keywords     = {CrowdTangle,Facebook,coordinated inauthentic behavior,disinformation}
}
@article{glmnet,
	title        = {{Regularization Paths for Generalized Linear Models via Coordinate Descent}},
	author       = {{Jerome Friedman and Trevor Hastie and Robert Tibshirani}},
	year         = 2010,
	journal      = {Journal of Statistical Software},
	volume       = 33,
	number       = 1,
	pages        = {1--22}
}
@article{Goerzen2019,
	title        = {{Black hat trolling, white hat trolling, and hacking the attention landscape}},
	author       = {{Matthews, Jeanna and Goerzen, Matthew}},
	year         = 2019,
	journal      = {The Web Conference 2019 -- Companion of the World Wide Web Conference, WWW 2019},
	volume       = 2,
	pages        = {523--528},
	doi          = {https://doi.org/10.1145/3308560.3317598}
}
@article{Goldenberg2001,
	title        = {{Talk of the Network: A Complex Systems Look at the Underlying Process of Word-of-Mouth}},
	author       = {{Goldenberg, Jacob and Libai, Barak and Muller, Eitan}},
	year         = 2001,
	month        = {Aug},
	journal      = {Marketing Letters},
	volume       = 12,
	number       = 3,
	pages        = {211--223},
	issn         = {1573-059X}
}
@article{goodman2020friction,
	title        = {{Digital Information Fidelity and Friction}},
	author       = {{Goodman, Ellen P}},
	year         = 2020,
	journal      = {Knight First Amendment Institute at Columbia University. https://knightcolumbia. org/content/digital-fidelity-and-friction (accessed January 7, 2021)}
}
@article{gorwa2020unpacking,
	title        = {{Unpacking the social media bot: A typology to guide research and policy}},
	author       = {{Gorwa, Robert and Guilbeault, Douglas}},
	year         = 2020,
	journal      = {Policy \& Internet},
	publisher    = {Wiley Online Library},
	volume       = 12,
	number       = 2,
	pages        = {225--248}
}
@report{Graham2020,
	title        = {{Like a virus}},
	author       = {{Timothy Graham and Axel Bruns and Guangnan Zhu and Rod Campbell}},
	year         = 2020,
	url          = {https://www.tai.org.au}
}
@article{Granovetter1978,
	title        = {{Threshold Models of Collective Behavior}},
	author       = {{Granovetter, Mark}},
	year         = 1978,
	journal      = {American Journal of Sociology},
	volume       = 83,
	number       = 6,
	pages        = {1420--1443}
}
@article{Greenberg:2004,
	title        = {{Setting the public agenda for online health search: a white paper and action agenda}},
	author       = {{Greenberg, Liza and D'Andrea, Guy and Lorence, Dan}},
	year         = 2004,
	journal      = {Journal of Medical Internet Research},
	publisher    = {Gunther Eysenbach},
	volume       = 6,
	number       = 2,
	pages        = {e18},
	isbn         = {1438-8871}
}
@inproceedings{Grimme2018CoordUnsupervOwnBots,
	title        = {{Changing Perspectives: Is It Sufficient to Detect Social Bots?}},
	author       = {{Grimme, Christian and Assenmacher, Dennis and Adam, Lena}},
	year         = 2018,
	booktitle    = {{S}ocial {C}omputing and {S}ocial {M}edia. {U}ser {E}xperience and {B}ehavior},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	pages        = {445--461},
	editor       = {Meiselwitz, Gabriele},
	doiii        = {https://doi.org/10.1007/978-3-319-91521-0_32}
}
@article{Grofman1983,
	title        = {{Thirteen theorems in search of the truth}},
	author       = {{Grofman, Bernard and Owen, Guillermo and Feld, Scott L.}},
	year         = 1983,
	journal      = {Theory and Decision},
	volume       = 15,
	number       = 3,
	pages        = {261--278}
}
@article{Guille_2013,
	title        = {{Information Diffusion in Online Social Networks: A Survey}},
	author       = {{Guille, Adrien and Hacid, Hakim and Favre, Cecile and Zighed, Djamel A.}},
	year         = 2013,
	month        = jul,
	journal      = {SIGMOD Rec.},
	publisher    = {ACM},
	address      = {New York, NY, USA},
	volume       = 42,
	number       = 2,
	pages        = {17--28},
	issn         = {0163-5808}
}
@article{Guimaraes2021,
	title        = {{Towards a pragmatic detection of unreliable accounts on social networks}},
	author       = {{Guimar\~{a}es, Nuno and Figueira, \'{A}lvaro and Torgo, Lu\'{i}s}},
	year         = 2021,
	journal      = {Online Social Networks and Media},
	publisher    = {Elsevier B.V.},
	volume       = 24,
	number       = {June},
	pages        = 100152,
	issn         = 24686964,
	keywords     = {Data mining,Machine learning,Social networks,Unreliable accounts detection,Volume and time adaptive methodology}
}
@article{Hagen2022_risesocialbot,
	title        = {{Rise of the Machines? Examining the Influence of Social Bots on a Political Discussion Network}},
	author       = {{Loni Hagen and Stephen Neely and Thomas E. Keller and Ryan Scharf and Fatima Espinoza Vasquez}},
	year         = 2022,
	journal      = {Social Science Computer Review},
	volume       = 40,
	number       = 2,
	pages        = {264--287}
}
@article{harff2022responses,
	title        = {{Responses to Social Media Influencers’ Misinformation about COVID-19: A Pre-Registered Multiple-Exposure Experiment}},
	author       = {{Harff, Darian and Bollen, Charlotte and Schmuck, Desiree}},
	year         = 2022,
	journal      = {Media Psychology},
	publisher    = {Taylor \& Francis},
	pages        = {1--20}
}
@book{hastie_09_elements-of.statistical-learning,
	title        = {{The Elements of Statistical Learning: Data Mining, Inference and Prediction}},
	author       = {{Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome}},
	year         = 2009,
	publisher    = {Springer},
	doi          = {https://doi.org/10.1007/978-0-387-84858-7},
	edition      = {2nd}
}
@article{Hegelich2016,
	title        = {{Are social bots on Twitter political actors? Empirical evidence from a Ukrainian social botnet}},
	author       = {{Hegelich, Simon and Janetzko, Dietmar}},
	year         = 2016,
	journal      = {Proceedings of the 10th International Conference on Web and Social Media, ICWSM 2016},
	number       = {Icwsm},
	pages        = {579--582},
	isbn         = 9781577357582
}
@inproceedings{Heidari2021,
	title        = {{An empirical study of machine learning algorithms for social media bot detection}},
	author       = {{Maryam Heidari and James H.J. Jones and Ozlem Uzuner}},
	year         = 2021,
	month        = 4,
	journal      = {2021 IEEE International IOT, Electronics and Mechatronics Conference, IEMTRONICS 2021 - Proceedings},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	doi          = {10.1109/IEMTRONICS52119.2021.9422605},
	isbn         = 9781665440677,
	abstract     = {Social media bots can change society's perspective in different aspects of life. This paper analyzes sentiment features and their effect on the accuracy of machine learning models for social media bot detection. Social bots can use tweet sentiment to create a backfire effect and confirmation bias to create a fake trend or change public opinion. We analyze bot detection problems based on sentiment features inspired by the work by Micheal Workman [1] and create new features based on textual information of online comments. We offer a quantitative approach to create new features and compare machine learning models for bot detection. This work is based on psychological and social effects inherent in tweets' text content based on the work by [1]. The new set of sentiment features are extracted from a tweet's text and used to train bot detection models. Also, we implement the new model for the Dutch language and achieve more than 87% accuracy for the Dutch tweets based on new sentiment features. Considering new sentiment features based on psychological and social factors for a tweet's text will open a potential research area for social media bot detection.},
	keywords     = {Bot detection,Deep learning,Social factors,Social media bot}
}
@article{hemphill2022comparative,
	title        = {{Comparative sensitivity of social media data and their acceptable use in research}},
	author       = {{Hemphill, Libby and Sch\"o}pke-Gonzalez, Angela and Panda, Anmol}},
	year         = 2022,
	journal      = {Scientific Data},
	publisher    = {Nature Publishing Group},
	volume       = 9,
	number       = 1,
	pages        = {1--14}
}
@article{Hendricks2021,
	title        = {{Turning the Tables: Using BigTech community standards as friction strategies}},
	author       = {{Vincent Hendricks}},
	year         = 2021,
	journal      = {OECD The Forum Network},
	volume       = {December 20},
	number       = {},
	pages        = {},
	url          = {https://www.oecd-forum.org/posts/turning-the-tables-using-bigtech-community-standards-as-friction-strategies}
}
@book{HendricksMehlsen2022,
	title        = {{The Ministry of Truth: BigTech's Influence on Facts, Feelings and Fiction}},
	author       = {{Hendricks, Vincent F. and Mehlsen, Camilla}},
	year         = {2022 forthcoming},
	publisher    = {Springer Nature}
}
@book{HendricksVestergaard2019,
	title        = {{Reality Lost: Markets of Attention, Misinformation and Manipulation}},
	author       = {{Hendricks, Vincent F. and Vestergaard, Mads}},
	year         = 2019,
	publisher    = {Springer Nature}
}
@article{henkel2011reading,
	title        = {{Reading is believing: The truth effect and source credibility}},
	author       = {{Henkel, Linda A and Mattson, Mark E}},
	year         = 2011,
	journal      = {Consciousness and cognition},
	publisher    = {Elsevier},
	volume       = 20,
	number       = 4,
	pages        = {1705--1721}
}
@article{hills2019dark,
	title        = {{The dark side of information proliferation}},
	author       = {{Hills, Thomas T}},
	year         = 2019,
	journal      = {Perspectives on Psychological Science},
	publisher    = {Sage Publications Sage CA: Los Angeles, CA},
	volume       = 14,
	number       = 3,
	pages        = {323--330}
}
@article{holtz2018using,
	title        = {{Using big data techniques for measuring productive friction in mass collaboration online environments}},
	author       = {{Holtz, Peter and Kimmerle, Joachim and Cress, Ulrike}},
	year         = 2018,
	journal      = {International Journal of Computer-Supported Collaborative Learning},
	publisher    = {Springer},
	volume       = 13,
	number       = 4,
	pages        = {439--456}
}
@inproceedings{Huang2015,
	title        = {{Information cascades in social networks via dynamic system analyses}},
	author       = {{S. Huang and K. Chen}},
	year         = 2015,
	month        = {June},
	booktitle    = {2015 IEEE International Conference on Communications (ICC)},
	volume       = {},
	number       = {},
	pages        = {1262--1267},
	issn         = {1550-3607}
}
@article{ikram2015_fblikefarms,
	title        = {{Combating Fraud in Online Social Networks: Detecting Stealthy Facebook Like Farms}},
	author       = {{Ikram, Muhammad and Onwuzurike, Lucky and Farooqi, Shehroze and De Cristofaro, Emiliano and Friedman, Arik and Jourjon, Guillaume and Kaafar, Mohammad Ali and Shafiq, M Zubair}},
	year         = 2015,
	journal      = {arXiv preprint arXiv:1506.00506}
}
@article{ikram2017_fblikefarms,
	title        = {{Measuring, characterizing, and detecting Facebook like farms}},
	author       = {{Ikram, Muhammad and Onwuzurike, Lucky and Farooqi, Shehroze and Cristofaro, Emiliano De and Friedman, Arik and Jourjon, Guillaume and Kaafar, Mohammed Ali and Shafiq, M Zubair}},
	year         = 2017,
	journal      = {ACM Transactions on Privacy and Security (TOPS)},
	publisher    = {ACM New York, NY, USA},
	volume       = 20,
	number       = 4,
	pages        = {1--28},
	doi          = {https://doi.org/10.1145/3121134}
}
@article{InfoandDemocracy_policy2018,
	title        = {{Policy Framework: Working Group on Infodemics}},
	author       = {{Ressa, Maria and Schaake, Marietje and Halgand-Mishra, Delphine and de Villars, Iris and Domino, Jenny and Shefet, Dan}},
	year         = 2018,
	journal      = {Forum on Information and Democracy},
	publisher    = {Forum on Information and Democracy}
}
@article{jackson2022learning,
	title        = {{Learning through the grapevine and the impact of the breadth and depth of social networks}},
	author       = {{Jackson, Matthew O and Malladi, Suraj and McAdams, David}},
	year         = 2022,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 119,
	number       = 34,
	pages        = {e2205549119}
}
@article{juul2021cascadefakenews,
	title        = {{Comparing information diffusion mechanisms by matching on cascade size}},
	author       = {{Juul, Jonas L and Ugander, Johan}},
	year         = 2021,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 118,
	number       = 46,
	pages        = {e2100786118}
}
@article{juul2021comparing,
	title        = {{Comparing information diffusion mechanisms by matching on cascade size}},
	author       = {{Juul, Jonas L and Ugander, Johan}},
	year         = 2021,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 118,
	number       = 46,
	pages        = {e2100786118}
}
@article{Kaniovski2010,
	title        = {{Aggregation of correlated votes and Condorcet's Jury Theorem}},
	author       = {{Kaniovski, Serguei}},
	year         = 2010,
	journal      = {Theory and Decision},
	volume       = 69,
	number       = 3,
	pages        = {453--468}
}
@misc{katsaros2021reconsidering,
	title        = {{Reconsidering Tweets: Intervening During Tweet Creation Decreases Offensive Content}},
	author       = {{Matthew Katsaros and Kathy Yang and Lauren Fratamico}},
	year         = 2021,
	eprint       = {2112.00773},
	archiveprefix = {arXiv},
	primaryclass = {cs.SI}
}
@article{keller2020political,
	title        = {{Political astroturfing on Twitter: How to coordinate a disinformation campaign}},
	author       = {{Keller, Franziska B and Schoch, David and Stier, Sebastian and Yang, JungHwan}},
	year         = 2020,
	journal      = {Political Communication},
	publisher    = {Taylor \& Francis},
	volume       = 37,
	number       = 2,
	pages        = {256--280}
}
@article{kendall1945treatment,
	title        = {{The treatment of ties in ranking problems}},
	author       = {{Kendall, Maurice G}},
	year         = 1945,
	journal      = {Biometrika},
	publisher    = {JSTOR},
	volume       = 33,
	number       = 3,
	pages        = {239--251}
}
@article{Khaund2022_Socialbotcoord,
	title        = {{Social Bots and Their Coordination During Online Campaigns: A Survey}},
	author       = {{Khaund, Tuja and Kirdemir, Baris and Agarwal, Nitin and Liu, Huan and Morstatter, Fred}},
	year         = 2022,
	journal      = {IEEE Transactions on Computational Social Systems},
	volume       = 9,
	number       = 2,
	pages        = {530--545},
	doi          = {https://doi.org/10.1109/TCSS.2021.3103515}
}
@article{kirn2021bayesian,
	title        = {{Bayesian identification of bots using temporal analysis of tweet storms}},
	author       = {{Kirn, Spencer Lee and Hinders, Mark K}},
	year         = 2021,
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer},
	volume       = 11,
	number       = 1,
	pages        = {1--17}
}
@article{Kirn2022,
	title        = {{Ridge count thresholding to uncover coordinated networks during onset of the Covid-19 pandemic}},
	author       = {{Spencer Lee Kirn and Mark K. Hinders}},
	year         = 2022,
	month        = 12,
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer Science and Business Media LLC},
	volume       = 12,
	doi          = {https://doi.org/10.1007/s13278-022-00873-0},
	issn         = {1869-5450},
	issue        = 1,
	abstract     = {In order to combat information operations (IO) and disinformation campaigns, one must look at the behaviors of the accounts pushing specific narratives and stories through social media, not at the content itself. In this work, we present a new process for extracting tweet storms and uncovering networks of accounts that are working in a coordinated fashion using ridge count thresholding (RCT). To do this, we started with a dataset of 60 million individual tweets from the early weeks of the Covid-19 pandemic. Coherent topics are extracted from this data by testing three different preprocessing pipelines and applying Orthogonal Nonnegative Matrix Factorization (ONMF). The most effective preprocessing pipeline used hashtag preclustering to downselect the total dataset to the 7 million tweets that included the top hashtags. Each topic identified by ONMF is described by a topic-tweet signal, crafted using the time stamp included in each tweet’s metadata. These signals were broken down into tweet storms using RCT, which is calculated from the Dynamic Wavelet Fingerprint transform of each topic-tweet signal. Each tweet storm described a time of increased activity around a topic. Tweet storms identified in this way each represent some behavior in the underlying network. In total, we identified 39,817 total tweet storms that included about 2 million unique tweets. These tweet storms were used to identify networks of accounts that commonly co-occur within tweet storms to isolate those communities most responsible for driving narratives and pushing stories through social media. Through this process, we were able to identify 22 unique networks of accounts that were densely connected based on RCT tweet storm identification. Many of the identified networks exhibit obvious inauthentic behaviors that are potentially a part of an IO campaign.}
}
@book{KleinbergTardos2005,
	title        = {{Algorithm Design}},
	author       = {{Kleinberg, Jon and Tardos, \'{E}va}},
	year         = 2005,
	publisher    = {Pearson}
}
@article{kozyreva2022toolboxinterventions,
	title        = {{Toolbox of Interventions Against Online Misinformation and Manipulation}},
	author       = {{Kozyreva, Anastasia and Lorenz-Spreen, Philipp and Herzog, Stefan and Ecker, Ullrich and Lewandowsky, Stephan and Hertwig, Ralph}},
	year         = 2022,
	publisher    = {PsyArXiv}
}
@article{lacassagne2022illusionary,
	title        = {{Is Earth a perfect square? Repetition increases the perceived truth of highly implausible statements}},
	author       = {{Lacassagne, Doris and B\'e}na, J{\'e}r{\'e}my and Corneille, Olivier}}}},
	year         = 2022,
	journal      = {Cognition},
	publisher    = {Elsevier},
	volume       = 223,
	pages        = 105052
}
@article{LADHA1995,
	title        = {{Information pooling through majority-rule voting: Condorcet's jury theorem with correlated votes}},
	author       = {{Krishna K Ladha}},
	year         = 1995,
	journal      = {Journal of Economic Behavior \& Organization},
	volume       = 26,
	number       = 3,
	pages        = {353--372}
}
@article{Lazer2018,
	title        = {{The science of fake news}},
	author       = {{Lazer, David M. J. and Baum, Matthew A. and Benkler, Yochai and Berinsky, Adam J. and Greenhill, Kelly M. and Menczer, Filippo and Metzger, Miriam J. and Nyhan, Brendan and Pennycook, Gordon and Rothschild, David and Schudson, Michael and Sloman, Steven A. and Sunstein, Cass R. and Thorson, Emily A. and Watts, Duncan J. and Zittrain, Jonathan L.}},
	year         = 2018,
	journal      = {Science},
	volume       = 359,
	number       = 6380,
	pages        = {1094--1096},
	doi          = {https://doi.org/10.1126/science.aao2998}
}
@article{Lazer2020,
	title        = {{Studying human attention on the Internet}},
	author       = {{Lazer, David}},
	year         = 2020,
	journal      = {Proceedings of the National Academy of Sciences of the United States of America},
	volume       = 117,
	number       = 1,
	pages        = {21--22},
	issn         = 10916490
}
@article{Lee2019BBCInsta,
	title        = {{Instagram now asks bullies: 'Are you sure?'}},
	author       = {{Lee, Dave}},
	year         = 2019,
	journal      = {BBC news},
	url          = {https://www.bbc.com/news/technology-48916828}
}
@article{Lorenz-Spreen2020,
	title        = {{How behavioural sciences can promote truth, autonomy and democratic discourse online}},
	author       = {{Lorenz-Spreen, Philipp and Lewandowsky, Stephan and Sunstein, Cass R. and Hertwig, Ralph}},
	year         = 2020,
	journal      = {Nature Human Behaviour},
	publisher    = {Springer US},
	volume       = 4,
	number       = 11,
	pages        = {1102--1109},
	doi          = {https://doi.org/10.1038/s41562-020-0889-7}
}
@article{lorenz2011social,
	title        = {{How social influence can undermine the wisdom of crowd effect}},
	author       = {{Lorenz, Jan and Rauhut, Heiko and Schweitzer, Frank and Helbing, Dirk}},
	year         = 2011,
	journal      = {Proceedings of the national academy of sciences},
	publisher    = {National Acad Sciences},
	volume       = 108,
	number       = 22,
	pages        = {9020--9025}
}
@article{lorenz2020behavioural,
	title        = {{How behavioural sciences can promote truth, autonomy and democratic discourse online}},
	author       = {{Lorenz-Spreen, Philipp and Lewandowsky, Stephan and Sunstein, Cass R and Hertwig, Ralph}},
	year         = 2020,
	journal      = {Nature human behaviour},
	publisher    = {Nature Publishing Group},
	volume       = 4,
	number       = 11,
	pages        = {1102--1109}
}
@article{lou2019manipulating,
	title        = {{Manipulating the online marketplace of ideas}},
	author       = {{Lou, Xiaodan and Flammini, Alessandro and Menczer, Filippo}},
	year         = 2019,
	journal      = {arXiv preprint arXiv:1907.06130}
}
@article{Luceri2019,
	title        = {{Red bots do it better: Comparative analysis of social bot partisan behavior}},
	author       = {{Luceri, Luca and Badawy, Adam and Deb, Ashok and Ferrara, Emilio}},
	year         = 2019,
	month        = 5,
	journal      = {The Web Conference 2019 - Companion of the World Wide Web Conference, WWW 2019},
	publisher    = {Association for Computing Machinery, Inc},
	pages        = {1007--1012},
	doi          = {10.1145/3308560.3316735},
	isbn         = 9781450366755,
	eprint       = {1902.02765},
	keywords     = {Political elections,Political manipulation,Social bots,Social media},
	abstract     = {Recent research brought awareness of the issue of bots on social media and the significant risks of mass manipulation of public opinion in the context of political discussion. In this work, we leverage Twitter to study the discourse during the 2018 US midterm elections and analyze social bot activity and interactions with humans. We collected 2.6 million tweets for 42 days around the election day from nearly 1 million users. We use the collected tweets to answer three research questions: (i) Do social bots lean and behave according to a political ideology? (ii) Can we observe different strategies among liberal and conservative bots? (iii) How effective are bot strategies in engaging humans? We show that social bots can be accurately classified according to their political leaning and behave accordingly. Conservative bots share most of the topics of discussion with their human counterparts, while liberal bots show less overlap and a more inflammatory attitude. We studied bot interactions with humans and observed different strategies. Finally, we measured bots embeddedness in the social network and the extent of human engagement with each group of bots. Results show that conservative bots are more deeply embedded in the social network and more effective than liberal bots at exerting influence on humans.}
}
@article{LUTZKE2019,
	title        = {{Priming critical thinking: Simple interventions limit the influence of fake news about climate change on Facebook}},
	author       = {{Lauren Lutzke and Caitlin Drummond and Paul Slovic and Joseph \'A}rvai}},
	year         = 2019,
	journal      = {Global Environmental Change},
	volume       = 58,
	pages        = 101964,
	doi          = {https://doi.org/10.1016/j.gloenvcha.2019.101964},
	issn         = {0959-3780},
	url          = {https://www.sciencedirect.com/science/article/pii/S0959378019307009},
	keywords     = {Fake news, Social media, Climate change, Facebook, Critical thinking},
	abstract     = {Fake news about climate change refers to fabricated information that mimics the appearance of legitimate reporting but is intended to mislead consumers. In light of concerns about fake news regarding climate change and other topics, researchers and media providers have been searching for ways to limit its spread and influence. This study tested the effect of two simple interventions, both of which primed critical thinking, on individuals’ evaluation of the credibility of real and fake news about climate change on Facebook. Through an online experiment (n = 2,750 participants), participants either read a series of guidelines for evaluating news online, or read and then rated the importance of each guideline; a control group was not exposed to guidelines of any type. We found that participants exposed to both types of guidelines reported a reduced likelihood to trust, like, and share fake news about climate change on Facebook. Importantly, exposure to these guidelines did not diminish individuals’ likelihood to trust, like, or share legitimate climate news. The effect sizes for both types of intervention were small. However, because of the scale and speed at which social media operates, even a small reduction in users’ likelihood to trust, like, and share fake news could be meaningful and impactful.}
}
@article{Magelinski2022,
	title        = {{Synchronized Action Framework for Detection of Coordination on Social Media}},
	author       = {{Thomas Magelinski and Lynnette Ng and Kathleen Carley}},
	year         = 2022,
	month        = 2,
	journal      = {Journal of Online Trust and Safety},
	publisher    = {Stanford Internet Observatory},
	volume       = 1,
	doi          = {https://doi.org/10.54501/jots.v1i2.30},
	issue        = 2,
	abstract     = {The study of the coordinated manipulation of conversations on social media has become more prevalent as social media’s role in amplifying misinformation, hate, and polarization has come under greater scrutiny. We discuss how successful generalized coordination detection algorithms could be used to reinforce existing power imbalances, such as those between marginalized groups and government agencies. We propose an alternative method of identifying manipulation—detecting synchronized actions—which reduces this risk. We further consider how responsible coordination detection may be carried out by analyzing synchronized actions. We propose a synchronized action framework for detecting automated coordination by constructing and analyzing multi-view networks. We validate our framework by examining a large Twitter dataset surrounding the Reopen America conversation from 2020. We first discover three simple coordinated campaigns, and then investigate synchronized actions between users discussing the protests that could be consistent with covert coordination. This task is far more complex than examples evaluated in prior work, which demonstrates the need for our multi-view approach. Next, we identify a cluster of suspicious users and detail the activity of three members. These three users amplify protest messages using the same hashtags at very similar times, though they all focus on different states. This analysis highlights the potential usefulness of coordination detection algorithms in investigating amplification, as well as the need to carefully and responsibly deploy such tools.}
}
@article{Martini2021,
	title        = {{Bot, or not? Comparing three methods for detecting social bots in five political discourses}},
	author       = {{Franziska Martini and Paul Samula and Tobias R. Keller and Ulrike Klinger}},
	year         = 2021,
	journal      = {Big Data and Society},
	publisher    = {SAGE Publications Ltd},
	volume       = 8,
	doi          = {https://doi.org/10.1177/20539517211033566},
	issn         = 20539517,
	issue        = 2,
	abstract     = {Social bots – partially or fully automated accounts on social media platforms – have not only been widely discussed, but have also entered political, media and research agendas. However, bot detection is not an exact science. Quantitative estimates of bot prevalence vary considerably and comparative research is rare. We show that findings on the prevalence and activity of bots on Twitter depend strongly on the methods used to identify automated accounts. We search for bots in political discourses on Twitter, using three different bot detection methods: Botometer, Tweetbotornot and “heavy automation”. We drew a sample of 122,884 unique user Twitter accounts that had produced 263,821 tweets contributing to five political discourses in five Western democracies. While all three bot detection methods classified accounts as bots in all our cases, the comparison shows that the three approaches produce very different results. We discuss why neither manual validation nor triangulation resolves the basic problems, and conclude that social scientists studying the influence of social bots on (political) communication and discourse dynamics should be careful with easy-to-use methods, and consider interdisciplinary research.},
	keywords     = {Social bots,Twitter,bot detection,comparative research,political discourse}
}
@article{matias2019commstandardsreddit,
	title        = {{Preventing harassment and increasing group participation through social norms in 2,190 online science discussions}},
	author       = {{Matias, J Nathan}},
	year         = 2019,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Acad Sciences},
	volume       = 116,
	number       = 20,
	pages        = {9785--9789}
}
@article{Matthews2020a,
	title        = {{How fake accounts constantly manipulate what you see on social media -- and what you can do about it}},
	author       = {{Jeanna Matthews}},
	year         = 2020,
	journal      = {The Conversation},
	volume       = {June 24},
	number       = {},
	pages        = {},
	url          = {https://theconversation.com/how-fake-accounts-constantly-manipulate-what-you-see-on-social-media-and-what-you-can-do-about-it-139610}
}
@inproceedings{mazza2019rtbust,
	title        = {{Rtbust: Exploiting Temporal Patterns for Botnet Detection on Twitter}},
	author       = {{Mazza, Michele and Cresci, Stefano and Avvenuti, Marco and Quattrociocchi, Walter and Tesconi, Maurizio}},
	year         = 2019,
	booktitle    = {Proceedings of the 10th ACM conference on web science},
	pages        = {183--192}
}
@article{MCGREW2020,
	title        = {{Learning to evaluate: An intervention in civic online reasoning}},
	author       = {{Sarah McGrew}},
	year         = 2020,
	journal      = {Computers & Education},
	volume       = 145,
	pages        = 103711,
	doi          = {https://doi.org/10.1016/j.compedu.2019.103711},
	issn         = {0360-1315},
	url          = {https://www.sciencedirect.com/science/article/pii/S0360131519302647},
	keywords     = {Online reasoning, Source evaluation, Media in education, Instructional intervention},
	abstract     = {Students turn to the Internet for information but often struggle to evaluate the trustworthiness of what they find. Teachers should help students develop effective evaluation strategies in order to ensure that students have access to reliable information on which to base decisions. This study reports on the results of an attempt to teach students to reason about online information. Students were taught strategies for evaluating digital content that were based on the practices of professional fact checkers. Eight lessons were devoted to teaching students strategies to effectively evaluate digital content. Pre- and posttests, each composed of four brief, constructed-response items, were administered to 68 11th-grade students who participated in the study. Students' scores improved significantly from pre-to posttest on three of the four tasks: students demonstrated an improved ability to investigate the source of a website, critique evidence, and locate reliable sources during an open Internet search. These results are promising and suggest that explicit instruction on fact-checking strategies may help students develop more effective online evaluation strategies.}
}
@article{mclust,
	title        = {{mclust 5: clustering, classification and density estimation using Gaussian finite mixture models}},
	author       = {{Luca Scrucca and Michael Fop and T. Brendan Murphy and Adrian E. Raftery}},
	year         = 2016,
	journal      = {The {R} Journal},
	volume       = 8,
	number       = 1,
	pages        = {289--317},
	doi          = {http://dx.doi.org/10.32614/RJ-2016-021}
}
@article{MCSpaper,
	title        = {{Detecting Coordinated Inauthentic Behavior in Likes on Social Media: Proof of Concept}},
	author       = {{Jahn, Laura and Rendsvig, Rasmus~K. and St\ae}rk-{\O}stergaard, Jacob}}},
	year         = 2022,
	journal      = {Under Review}
}
@misc{Menczer2021Conversation,
	title        = {{Facebook whistleblower Frances Haugen testified that the company's algorithms are dangerous -- here's how they can manipulate you}},
	author       = {{Menczer, Filippo}},
	year         = 2021,
	month        = {Oct-Nov},
	url          = {https://theconversation.com/facebook-whistleblower-frances-haugen-testified-that-the-companys-algorithms-are-dangerous-heres-how-they-can-manipulate-you-169420},
	date-added   = {2021-10-28 19:51:02 -0400},
	date-modified = {2022-01-10 19:32:04 -0500},
	howpublished = {The Conversation},
	keywords     = {myown abuse social osome networks crowdsourcing},
	bdsk-url-1   = {https://theconversation.com/facebook-whistleblower-frances-haugen-testified-that-the-companys-algorithms-are-dangerous-heres-how-they-can-manipulate-you-169420}
}
@article{MenczerHills2020SciAm,
	title        = {{The Attention Economy}},
	author       = {{Filippo Menczer and Thomas Hills}},
	year         = 2020,
	month        = {Dec},
	journal      = {Scientific American},
	volume       = 323,
	number       = 6,
	pages        = {54--61},
	doi          = {10.1038/scientificamerican1220-54},
	url          = {https://www.scientificamerican.com/article/information-overload-helps-fake-news-spread-and-social-media-knows-it/},
	date-added   = {2020-11-19 13:45:28 -0500},
	date-modified = {2022-01-11 01:16:41 -0500},
	keywords     = {abuse agents myown networks osome social},
	bdsk-url-1   = {https://www.scientificamerican.com/article/information-overload-helps-fake-news-spread-and-social-media-knows-it/},
	bdsk-url-2   = {https://doi.org/10.1038/scientificamerican1220-54}
}
@article{Metaxas2015,
	title        = {{What Do Retweets Indicate? Results from User Survey and Meta-Review of Research}},
	author       = {{Metaxas, P. T. and Mustafaraj, E. and Wong, K. and Zeng, L. and O'Keefe, M. and Finn, S.}},
	year         = 2015,
	journal      = {Proceedings of the 9th International Conference on Web and Social Media, ICWSM 2015},
	pages        = {658--661},
	isbn         = 9781577357339
}
@article{Miller2014,
	title        = {{Twitter spammer detection using data stream clustering}},
	author       = {{Zachary Miller and Brian Dickinson and William Deitrick and Wei Hu and Alex Hai Wang}},
	year         = 2014,
	month        = 3,
	journal      = {Information Sciences},
	volume       = 260,
	pages        = {64--73},
	doi          = {10.1016/j.ins.2013.11.016},
	issn         = {00200255},
	keywords     = {Clustering,Data stream,Spam detection,Twitter},
	abstract     = {The rapid growth of Twitter has triggered a dramatic increase in spam volume and sophistication. The abuse of certain Twitter components such as "hashtags", "mentions", and shortened URLs enables spammers to operate efficiently. These same features, however, may be a key factor in identifying new spam accounts as shown in previous studies. Our study provides three novel contributions. Firstly, previous studies have approached spam detection as a classification problem, whereas we view it as an anomaly detection problem. Secondly, 95 one-gram features from tweet text were introduced alongside the user information analyzed in previous studies. Finally, to effectively handle the streaming nature of tweets, two stream clustering algorithms, StreamKM++ and DenStream, were modified to facilitate spam identification. Both algorithms clustered normal Twitter users, treating outliers as spammers. Each of these algorithms performed well individually, with StreamKM++ achieving 99% recall and a 6.4% false positive rate; and DenStream producing 99% recall and a 2.8% false positive rate. When used in conjunction, these algorithms reached 100% recall and a 2.2% false positive rate, meaning that our system was able to identify 100% of the spammers in our test while incorrectly detecting only 2.2% of normal users as spammers. © 2013 Elsevier Inc. All rights reserved.}
}
@article{misinfo_data,
	title        = {{Tackling misinformation: What researchers could do with social media data}},
	author       = {{Pasquetto, Irene V. and Swire-Thompson, Briony and others}},
	year         = 2020,
	journal      = {HKS Misinformation Review},
	volume       = 1,
	number       = 8,
	doi          = {https://doi.org/10.37016/mr-2020-49},
	url          = {https://doi.org/10.37016/mr-2020-49},
	keywords     = {myown abuse osome social},
	date-added   = {2021-01-07 03:18:14 -0500},
	date-modified = {2021-01-07 03:44:49 -0500},
	bdsk-url-1   = {https://doi.org/10.37016/mr-2020-49}
}
@software{MockSocialMediaTool,
	title        = {{Mock Social Media Website Tool}},
	author       = {{Jagayat, Arvin and Gurkaran Boparai, Carson Pun and Becky L. Choma}},
	url          = {https://docs.studysocial.media},
	date         = {May 31, 2021}
}
@article{monstedLehmann2022,
	title        = {{Characterizing polarization in online vaccine discourse—A large-scale study}},
	author       = {{M\o}nsted, Bjarke and Lehmann, Sune}},
	year         = 2022,
	journal      = {PloS one},
	publisher    = {Public Library of Science San Francisco, CA USA},
	volume       = 17,
	number       = 2,
	pages        = {e0263746}
}
@article{morosoli2022identifyingmisinfodissemination,
	title        = {{Identifying the drivers behind the dissemination of online misinformation: a study on political attitudes and individual characteristics in the context of engaging with misinformation on social media}},
	author       = {{Morosoli, Sophie and Van Aelst, Peter and Humprecht, Edda and Staender, Anna and Esser, Frank}},
	year         = 2022,
	journal      = {American Behavioral Scientist},
	publisher    = {SAGE Publications Sage CA: Los Angeles, CA},
	pages        = {00027642221118300}
}
@article{Muchnik2013,
	title        = {{Social Influence Bias: A Randomized Experiment}},
	author       = {{Muchnik, Lev and Aral, Sinan and Taylor, Sean J.}},
	year         = 2013,
	journal      = {Science},
	volume       = 341,
	number       = 6146,
	pages        = {647--651}
}
@article{Mueen2019,
	title        = {{Taming social bots: Detection, exploration and measurement}},
	author       = {{Mueen, Abdullah and Chavoshi, Nikan and Minnich, Amanda}},
	year         = 2019,
	month        = 11,
	journal      = {International Conference on Information and Knowledge Management, Proceedings},
	publisher    = {Association for Computing Machinery},
	pages        = {2967--2968},
	doi          = {10.1145/3357384.3360315},
	isbn         = 9781450369763,
	keywords     = {Campaign,Link farming,Purge,Social bots},
	abstract     = {Social bots have been around since 2008, and thus, they have been polluting our online spaces for over a decade. Social bots are capable of swaying political opinion, spreading false information, and recruiting for terrorist organizations. Social bots use various sophisticated techniques by adopting emotions, sympathy following, synchronous deletions, and profile molting. There are several approaches proposed in the literature for detecting, exploring, and measuring of social bots. We provide a comprehensive overview of the existing work from the data mining and machine learning perspective, discuss relative strengths and weaknesses of various methods, make recommendations for researchers and practitioners, and propose novel directions for future research in taming social bots. This tutorial also discusses pitfalls in collecting and sharing data on social bots.}
}
@article{Najari2022,
	title        = {{GANBOT: a GAN-based framework for social bot detection}},
	author       = {{Najari, Shaghayegh and Salehi, Mostafa and Farahbakhsh, Reza}},
	year         = 2022,
	month        = 12,
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer Vienna},
	volume       = 12,
	number       = 1,
	pages        = {1--11},
	doi          = {10.1007/s13278-021-00800-9},
	isbn         = {0123456789},
	issn         = 18695469,
	keywords     = {Deep neural networks,Generative adversarial networks,Social bot detection,Text classification},
	abstract     = {Nowadays, a massive number of people are involved in various social media. This fact enables organizations and institutions to more easily access their audiences across the globe. Some of them use social bots as an automatic entity to gain intangible access and influence on their users by faster content propagation. Thereby, malicious social bots are populating more and more to fool humans with their unrealistic behavior and content. Hence, that’s necessary to distinguish these fake social accounts from real ones. Multiple approaches have been investigated in the literature to answer this problem. Statistical machine learning methods are one of them focusing on handcrafted features to represent characteristics of social bots. Although they reached successful results in some cases, they relied on the bot’s behavior and failed in the behavioral change patterns of bots. On the other hands, more advanced deep neural network-based methods aim to overcome this limitation. Generative adversarial network (GAN) as new technology from this domain is a semi-supervised method that demonstrates to extract the behavioral pattern of the data. In this work, we use GAN to leak more information of bot samples for state-of-the-art textual bot detection method (Contextual LSTM). Although GAN augments low labeled data, original textual GAN (Sequence Generative Adversarial Net (SeqGAN)) has the known limitation of convergence. In this paper, we invested this limitation and customized the GAN idea in a new framework called GANBOT, in which the generator and classifier connect by an LSTM layer as a shared channel between them. Our experimental results on a bench-marked dataset of Twitter social bot show our proposed framework outperforms the existing contextual LSTM method by increasing bot detection probabilities.},
	issue        = 1
}
@article{najari2022ganbot,
	title        = {{GANBOT: a GAN-based framework for social bot detection}},
	author       = {{Najari, Shaghayegh and Salehi, Mostafa and Farahbakhsh, Reza}},
	year         = 2022,
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer},
	volume       = 12,
	number       = 1,
	pages        = {1--11}
}
@article{nickerson1998confirmation,
	title        = {{Confirmation bias: A ubiquitous phenomenon in many guises}},
	author       = {{Nickerson, Raymond S}},
	year         = 1998,
	journal      = {Review of general psychology},
	publisher    = {SAGE Publications Sage CA: Los Angeles, CA},
	volume       = 2,
	number       = 2,
	pages        = {175--220}
}
@misc{NiemanLab_Norwayfriction,
	title        = {{This site is ``taking the edge off rant mode'' by making readers pass a quiz before commenting}},
	author       = {{Jospeh Lichtermann}},
	publisher    = {{Nieman Foundation at Harvard}},
	note         = {Accessed: 2022-12-05},
	howpublished = {\url{https://www.niemanlab.org/2017/03/this-site-is-taking-the-edge-off-rant-mode-by-making-readers-pass-a-quiz-before-commenting/}}
}
@article{nikolov2019quantifying,
	title        = {{Quantifying biases in online information exposure}},
	author       = {{Nikolov, Dimitar and Lalmas, Mounia and Flammini, Alessandro and Menczer, Filippo}},
	year         = 2019,
	journal      = {Journal of the Association for Information Science and Technology},
	publisher    = {Wiley Online Library},
	volume       = 70,
	number       = 3,
	pages        = {218--229}
}
@incollection{NIPS2015_5839,
	title        = {{Optimal Testing for Properties of Distributions}},
	author       = {{Acharya, Jayadev and Daskalakis, Constantinos and Kamath, Gautam}},
	year         = 2015,
	booktitle    = {Advances in Neural Information Processing Systems 28},
	publisher    = {Curran Associates, Inc.},
	pages        = {3591--3599},
	editor       = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett}
}
@article{Nizzoli2020,
	title        = {{Coordinated Behavior on Social Media in 2019 UK General Election}},
	author       = {{Leonardo Nizzoli and Serena Tardelli and Marco Avvenuti and Stefano Cresci and Maurizio Tesconi}},
	year         = 2020,
	month        = 8,
	url          = {http://arxiv.org/abs/2008.08370},
	abstract     = {Coordinated online behaviors are an essential part of information and influence operations, as they allow a more effective disinformation's spread. Most studies on coordinated behaviors involved manual investigations, and the few existing computational approaches make bold assumptions or oversimplify the problem to make it tractable. Here, we propose a new network-based framework for uncovering and studying coordinated behaviors on social media. Our research extends existing systems and goes beyond limiting binary classifications of coordinated and uncoordinated behaviors. It allows to expose different coordination patterns and to estimate the degree of coordination that characterizes diverse communities. We apply our framework to a dataset collected during the 2019 UK General Election, detecting and characterizing coordinated communities that participated in the electoral debate. Our work conveys both theoretical and practical implications and provides more nuanced and fine-grained results for studying online information manipulation.}
}
@inproceedings{nizzoli2021coordinated,
	title        = {{Coordinated Behavior on Social Media in 2019 UK General Election}},
	author       = {{Leonardo Nizzoli and Serena Tardelli and Marco Avvenuti and Stefano Cresci and Maurizio Tesconi}},
	year         = 2021,
	booktitle    = {Proc. International AAAI Conference on Web and Social Media (ICWSM)},
	volume       = 15,
	number       = 1,
	pages        = {443--454}
}
@incollection{olsson2013bayesian,
	title        = {{A Bayesian Simulation Model of Group Deliberation and Polarization}},
	author       = {{Olsson, Erik J}},
	year         = 2013,
	booktitle    = {Bayesian {A}rgumentation},
	publisher    = {Springer},
	pages        = {113--133},
	doi          = {http://dx.doi.org/10.1007/978-94-007-5357-0_6}
}
@article{Orabi2020,
	title        = {{Detection of Bots in Social Media: A Systematic Review}},
	author       = {{Orabi, Mariam and Mouheb, Djedjiga and Al Aghbari, Zaher and Kamel, Ibrahim}},
	year         = 2020,
	journal      = {Information Processing and Management},
	volume       = 57,
	doi          = {https://doi.org/10.1016/j.ipm.2020.102250},
	url          = {https://doi.org/10.1016/j.ipm.2020.102250}
}
@article{ostrom2008difference,
	title        = {{The Difference: How the Power of Diversity Creates Better Groups, Firms, Schools, and Societies. By Scott E. Page. Princeton: Princeton University Press, 2007. 448p. 19.95 paper.}},
	author       = {{Ostrom, Elinor}},
	year         = 2008,
	journal      = {Perspectives on Politics},
	publisher    = {Cambridge University Press},
	volume       = 6,
	number       = 4,
	pages        = {828--829}
}
@article{Pacheco2020,
	title        = {{Uncovering Coordinated Networks on Social Media: Methods and Case Studies}},
	author       = {{Diogo Pacheco and Pik-Mai Hui and Christopher Torres-Lugo and Bao Tran Truong and Alessandro Flammini and Filippo Menczer}},
	year         = 2020,
	month        = 1,
	url          = {http://arxiv.org/abs/2001.05658},
	abstract     = {Coordinated campaigns are used to influence and manipulate social media platforms and their users, a critical challenge to the free exchange of information online. Here we introduce a general, unsupervised network-based methodology to uncover groups of accounts that are likely coordinated. The proposed method constructs coordination networks based on arbitrary behavioral traces shared among accounts. We present five case studies of influence campaigns, four of which in the diverse contexts of U.S. elections, Hong Kong protests, the Syrian civil war, and cryptocurrency manipulation. In each of these cases, we detect networks of coordinated Twitter accounts by examining their identities, images, hashtag sequences, retweets, or temporal patterns. The proposed approach proves to be broadly applicable to uncover different kinds of coordination across information warfare scenarios.}
}
@inproceedings{Pacheco2021Coordinated,
	title        = {{Uncovering Coordinated Networks on Social Media: Methods and Case Studies}},
	author       = {{Diogo Pacheco and Pik-Mai Hui and Christopher Torres-Lugo and Truong, Bao Tran and Alessandro Flammini and Filippo Menczer}},
	year         = 2021,
	booktitle    = {Proc. International AAAI Conference on Web and Social Media (ICWSM)},
	volume       = 15,
	number       = 1,
	pages        = {455--466}
}
@misc{pennycook_mcphetres_zhang_lu_rand_2020,
	title        = {{Fighting COVID-19 misinformation on social media: Experimental evidence for a scalable accuracy nudge intervention}},
	author       = {{Pennycook, Gordon and McPhetres, Jonathon and Zhang, Yunhao and Lu, Jackson G and Rand, David G}},
	year         = 2020,
	month        = {Mar},
	publisher    = {PsyArXiv},
	doi          = {10.31234/osf.io/uhbk9},
	url          = {psyarxiv.com/uhbk9}
}
@article{Pennycook2019,
	title        = {{Fake news fast and slow}},
	author       = {{Pennycook, Gordon}},
	year         = 2019,
	journal      = {Journal of Experimental Psychology: General},
	pages        = {1--18},
	abstract     = {What role does deliberation play in susceptibility to political misinformation and "fake news"? The Motivated System 2 Reasoning (MS2R) account posits that deliberation causes people to fall for fake news, because reasoning facilitates identity-protective cognition and is therefore used to rationalize content that is consistent with one's political ideology. The classical account of reasoning instead posits that people ineffectively discern between true and false news headlines when they fail to deliberate (and instead rely on intuition). To distinguish between these competing accounts, we investigated the causal effect of reasoning on media truth discernment using a 2-response paradigm. Participants (N 1,635 Mechanical Turkers) were presented with a series of headlines. For each, they were first asked to give an initial, intuitive response under time pressure and concurrent working memory load. They were then given an opportunity to rethink their response with no constraints, thereby permitting more deliberation. We also compared these responses to a (deliberative) 1-response baseline condition where participants made a single choice with no constraints. Consistent with the classical account, we found that deliberation corrected intuitive mistakes: Participants believed false headlines (but not true headlines) more in initial responses than in either final responses or the unconstrained 1-response baseline. In contrast-and inconsistent with the Motivated System 2 Reasoning account-we found that political polarization was equivalent across responses. Our data suggest that, in the context of fake news, deliberation facilitates accurate belief formation and not partisan bias.}
}
@article{pennycook2020implied,
	title        = {{The implied truth effect: Attaching warnings to a subset of fake news headlines increases perceived accuracy of headlines without warnings}},
	author       = {{Pennycook, Gordon and Bear, Adam and Collins, Evan T and Rand, David G}},
	year         = 2020,
	journal      = {Management Science},
	publisher    = {INFORMS},
	volume       = 66,
	number       = 11,
	pages        = {4944--4957}
}
@article{Pennycook2021,
	title        = {{Shifting attention to accuracy can reduce misinformation online}},
	author       = {{Pennycook, Gordon and Epstein, Ziv and Mosleh, Mohsen and Arechar, Antonio A. and Eckles, Dean and Rand, David G.}},
	year         = 2021,
	journal      = {Nature},
	volume       = 592,
	number       = 7855,
	pages        = {590--595},
	doi          = {10.1038/s41586-021-03344-2},
	issn         = 14764687,
	file         = {:Users/qbj218/Dropbox/Laura/Friction Strategies/Lit/Academic/2021{\_}Pennycook et al - Shifting attention to accuracy - Nature unformatted.pdf:pdf},
	pmid         = 33731933
}
@article{pennycook2022accuracy,
	title        = {{Accuracy prompts are a replicable and generalizable approach for reducing the spread of misinformation}},
	author       = {{Pennycook, Gordon and Rand, David G}},
	year         = 2022,
	journal      = {Nature Communications},
	publisher    = {Nature Publishing Group},
	volume       = 13,
	number       = 1,
	pages        = {1--12}
}
@misc{PennycookRand2020_NYT,
	title        = {{The Right Way to Fight Fake News}},
	author       = {{Pennycook, Gordon and Rand, David}},
	year         = 2020,
	booktitle    = {The New York Times},
	url          = {https://www.nytimes.com/2020/03/24/opinion/fake-news-social-media.html}
}
@article{pfeffer2022TwitterresearchAPIcomplete,
	title        = {{This Sample seems to be good enough! Assessing Coverage and Temporal Reliability of Twitter's Academic API}},
	author       = {{Pfeffer, Juergen and Mooseder, Angelina and Hammer, Luca and Stritzel, Oliver and Garcia, David}},
	year         = {forthcoming, 2023},
	journal      = {Proceedings of the International Conference on Web and Social Media, ICWSM 2023}
}
@article{Pivato2017,
	title        = {{Epistemic democracy with correlated voters}},
	author       = {{Marcus Pivato}},
	year         = 2017,
	journal      = {Journal of Mathematical Economics},
	volume       = 72,
	pages        = {51--69}
}
@article{Poole2000,
	title        = {{Nonparametric Unfolding of Binary Choice Data}},
	author       = {{Poole, Keith T.}},
	year         = 2000,
	journal      = {Political Analysis},
	volume       = 8,
	number       = 3,
	pages        = {211--237},
	doi          = {https://doi.org/10.1093/oxfordjournals.pan.a029814}
}
@article{Porter2005,
	title        = {{A network analysis of committees in the U.S. House of Representatives}},
	author       = {{Porter, Mason A. and Mucha, Peter J. and Newman, M. E.J. and Warmbrand, Casey M.}},
	year         = 2005,
	journal      = {Proceedings of the National Academy of Sciences of the United States of America},
	volume       = 102,
	number       = 20,
	pages        = {7057--7062},
	doi          = {https://doi.org/10.1073/pnas.0500191102}
}
@inproceedings{prakash2010eigenspokes,
	title        = {{Eigenspokes: Surprising patterns and scalable community chipping in large graphs}},
	author       = {{Prakash, B Aditya and Sridharan, Ashwin and Seshadri, Mukund and Machiraju, Sridhar and Faloutsos, Christos}},
	year         = 2010,
	booktitle    = {Pacific-Asia Conference on Knowledge Discovery and Data Mining},
	pages        = {435--448},
	organization = {Springer}
}
@article{PreMarket2018,
	title        = {{Evaluating the replicability of social science experiments in Nature and Science between 2010 and 2015}},
	author       = {{C.~F. Camerer and A. Dreber and F. Holzmeister and T. Ho and J. Huber and M. Johannesson M. Kirchler and G. Nave and B.~A. Nosek and T. Pfeiffer and A. Altmejd and N. Buttrick and T. Chan and Y. Chen and E. Forsell and A. Gampa and E. Heikensten and L. Hummer and T. Imai and S. Isaksson and D. Manfredi and J. Rose and E. Wagenmakers and H. Wu}},
	year         = 2018,
	journal      = {Nature Human Behavior},
	volume       = 2,
	pages        = {637--644}
}
@article{qiu2017limited,
	title        = {{Limited individual attention and online virality of low-quality information}},
	author       = {{Qiu, Xiaoyan and FM Oliveira, Diego and Sahami Shirazi, Alireza and Flammini, Alessandro and Menczer, Filippo}},
	year         = 2017,
	journal      = {Nature Human Behaviour},
	publisher    = {Nature Publishing Group},
	volume       = 1,
	number       = 7,
	pages        = {1--7}
}
@article{Raafat2009,
	title        = {{Herding in humans}},
	author       = {{Ramsey M. Raafat and Nick Chater and Chris Frith}},
	year         = 2009,
	journal      = {Trends in Cognitive Sciences},
	volume       = 13,
	number       = 10,
	pages        = {420--428},
	issn         = {1364-6613}
}
@article{Ratkiewicz2011,
	title        = {{Detecting and Tracking Political Abuse in Social Media}},
	author       = {{Ratkiewicz, Jacob and Meiss, Mark and Conover, Michael and Gon\c{c}alves, Bruno and Flammini, Alessandro and Menczer, Filippo}},
	year         = 2011,
	journal      = {Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media},
	pages        = 297
}
@article{Rendsvig_BS,
	title        = {{Pluralistic ignorance in the bystander effect: Informational dynamics of unresponsive witnesses in situations calling for intervention}},
	author       = {{Rendsvig, Rasmus K.}},
	year         = 2014,
	journal      = {Synthese},
	volume       = 191,
	number       = 11,
	pages        = {2471--2498},
	issn         = {0039-7857}
}
@inproceedings{Rendsvig2012a,
	title        = {{Modeling Semantic Competence: A Critical Review of Frege's Puzzle about Identity}},
	author       = {{Rasmus~K. Rendsvig}},
	year         = 2012,
	booktitle    = {New Directions in Logic, Language and Computation},
	publisher    = {Springer},
	series       = {{Lecture Notes in Computer Science}},
	volume       = 7415,
	pages        = {140--157},
	editor       = {Daniel Lassiter and Marija Slavkovik}
}
@inproceedings{Rendsvig2012b,
	title        = {{Using Quantified Epistemic Logic as a Modeling Tool in Cognitive Neuropsychology}},
	author       = {{Rasmus~K. Rendsvig}},
	year         = 2012,
	booktitle    = {Proceedings of the Logic \& Cognition Workshop at ESSLLI 2012},
	publisher    = {CEUR Workshop Proceedings},
	pages        = {48--59},
	editor       = {Jakub Szymanik and Rineke Verbrugge}
}
@inproceedings{Rendsvig2013,
	title        = {{Aggregated Beliefs and Informational Cascades}},
	author       = {{Rasmus~K. Rendsvig}},
	year         = 2013,
	booktitle    = {Logic, Rationality, and Interaction (LORI 2013)},
	publisher    = {Springer},
	series       = {{Lecture Notes in Computer Science}},
	volume       = 8196,
	pages        = {337--341},
	editor       = {D. Grossi and O. Roy and H. Huang}
}
@inproceedings{Rendsvig2014,
	title        = {{Diffusion, Influence and Best-Response Dynamics in Networks: An Action Model Approach}},
	author       = {{Rendsvig, Rasmus K.}},
	year         = 2014,
	booktitle    = {Proceedings of the ESSLLI 2014 Student Session},
	publisher    = {arXiv:1708.01477},
	pages        = {63--75},
	editor       = {de Haan, Ronald}
}
@article{Rheault2021,
	title        = {{Efficient detection of online communities and social bot activity during electoral campaigns}},
	author       = {{Ludovic Rheault and Andreea Musulan}},
	year         = 2021,
	journal      = {Journal of Information Technology and Politics},
	publisher    = {Routledge},
	volume       = 18,
	pages        = {324--337},
	doi          = {10.1080/19331681.2021.1879705},
	issn         = {1933169X},
	abstract     = {Threats of social media manipulation during elections have become a central concern for modern democracies. This study tackles the problem of identifying the purpose and origins of social bots during electoral campaigns. We propose a methodology–uniform manifold approximation and projection combined with user-level document embeddings–that efficiently reveals the community structure of social media users. We show that this method can be used to predict the partisan affiliation of social media users with high accuracy, detect anomalous concentrations of social bots, and infer their geographical origin. We illustrate the methodology using Twitter data from the 2019 Canadian electoral campaign. Our evidence supports the thesis that social bots have become an integral component of campaign strategy for national actors. We also demonstrate how the methodology can be deployed to identify clusters of foreign bots, and we show that such accounts were used to share far-right and environment-related content during the campaign.},
	issue        = 3,
	keywords     = {Social bots,Twitter,elections,fake news,foreign interference,social media user embeddings}
}
@inproceedings{romanov2017detection_fakeprofiles,
	title        = {{Detection of fake profiles in social media-Literature review}},
	author       = {{Romanov, Aleksei and Semenov, Alexander and Mazhelis, Oleksiy and Veijalainen, Jari}},
	year         = 2017,
	booktitle    = {International Conference on Web Information Systems and Technologies},
	volume       = 2,
	pages        = {363--369},
	organization = {SCITEPRESS}
}
@article{ryczko2017hashkat,
	title        = {{Hashkat: large-scale simulations of online social networks}},
	author       = {{Ryczko, Kevin and Domurad, Adam and Buhagiar, Nicholas and Tamblyn, Isaac}},
	year         = 2017,
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer},
	volume       = 7,
	number       = 1,
	pages        = {1--13},
	doi          = {https://doi.org/10.1007/s13278-017-0424-7}
}
@article{samper2021bot,
	title        = {{Bot Datasets on Twitter: Analysis and Challenges}},
	author       = {{Samper-Escalante, Luis Daniel and Loyola-Gonz\'a}lez, Octavio and Monroy, Ra{\'u}l and Medina-P{\'e}rez, Miguel Angel}}}},
	year         = 2021,
	journal      = {Applied Sciences},
	publisher    = {MDPI},
	volume       = 11,
	number       = 9,
	pages        = 4105,
	doi          = {https://doi.org/10.3390/app11094105}
}
@article{Schoch2022,
	title        = {{Coordination patterns reveal online political astroturfing across the world}},
	author       = {{David Schoch and Franziska B. Keller and Sebastian Stier and Jung Hwan Yang}},
	year         = 2022,
	month        = 12,
	journal      = {Scientific Reports},
	publisher    = {Nature Research},
	volume       = 12,
	doi          = {https://doi.org/10.1038/s41598-022-08404-9},
	issn         = 20452322,
	issue        = 1,
	pmid         = 35301344,
	abstract     = {Online political astroturfing—hidden information campaigns in which a political actor mimics genuine citizen behavior by incentivizing agents to spread information online—has become prevalent on social media. Such inauthentic information campaigns threaten to undermine the Internet’s promise to more equitable participation in public debates. We argue that the logic of social behavior within the campaign bureaucracy and principal–agent problems lead to detectable activity patterns among the campaign’s social media accounts. Our analysis uses a network-based methodology to identify such coordination patterns in all campaigns contained in the largest publicly available database on astroturfing published by Twitter. On average, 74% of the involved accounts in each campaign engaged in a simple form of coordination that we call co-tweeting and co-retweeting. Comparing the astroturfing accounts to various systematically constructed comparison samples, we show that the same behavior is negligible among the accounts of regular users that the campaigns try to mimic. As its main substantive contribution, the paper demonstrates that online political astroturfing consistently leaves similar traces of coordination, even across diverse political and country contexts and different time periods. The presented methodology is a reliable first step for detecting astroturfing campaigns.}
}
@article{SHAHI2021misinformcovid19twitter,
	title        = {{An exploratory study of COVID-19 misinformation on Twitter}},
	author       = {{Gautam Kishore Shahi and Anne Dirkson and Tim A. Majchrzak}},
	year         = 2021,
	journal      = {Online Social Networks and Media},
	volume       = 22,
	pages        = 100104,
	doi          = {https://doi.org/10.1016/j.osnem.2020.100104},
	issn         = {2468-6964},
	url          = {https://www.sciencedirect.com/science/article/pii/S2468696420300458},
	keywords     = {Misinformation, Twitter, Social media, COVID-19, Fake news, Coronavirus, Diffusion of information},
	abstract     = {During the COVID-19 pandemic, social media has become a home ground for misinformation. To tackle this infodemic, scientific oversight, as well as a better understanding by practitioners in crisis management, is needed. We have conducted an exploratory study into the propagation, authors and content of misinformation on Twitter around the topic of COVID-19 in order to gain early insights. We have collected all tweets mentioned in the verdicts of fact-checked claims related to COVID-19 by over 92 professional fact-checking organisations between January and mid-July 2020 and share this corpus with the community. This resulted in 1500 tweets relating to 1274 false and 226 partially false claims, respectively. Exploratory analysis of author accounts revealed that the verified twitter handle(including Organisation/celebrity) are also involved in either creating(new tweets) or spreading(retweet) the misinformation. Additionally, we found that false claims propagate faster than partially false claims. Compare to a background corpus of COVID-19 tweets, tweets with misinformation are more often concerned with discrediting other information on social media. Authors use less tentative language and appear to be more driven by concerns of potential harm to others. Our results enable us to suggest gaps in the current scientific coverage of the topic as well as propose actions for authorities and social media users to counter misinformation.}
}
@article{Shahid2022,
	title        = {{Are You a Cyborg, Bot or Human?-A Survey on Detecting Fake News Spreaders}},
	author       = {{Wajiha Shahid and Yiran Li and Dakota Staples and Gulshan Amin and Saqib Hakak and Ali Ghorbani}},
	year         = 2022,
	journal      = {IEEE Access},
	publisher    = {Institute of Electrical and Electronics Engineers Inc.},
	volume       = 10,
	pages        = {27069--27083},
	doi          = {10.1109/ACCESS.2022.3157724},
	issn         = 21693536,
	keywords     = {Cyborg,deceptive content,deep fake,fake news detection,malicious user,misinformation,news propaganda,social bots,social media},
	abstract     = {One of the major components of Societal Digitalization is Online social networks (OSNs). OSNs can expose people to different popular trends in various aspects of life and alter people's beliefs, behaviors, and decisions and communication. Social bots and malicious users are the significant sources for spreading misinformation on social media and can pose serious cyber threats in society. The degree of similarity of user profiles of a cyber bot and a malicious user spreading fake news is so great that it is very difficult to differentiate both based on their attributes. Over the years, researchers have attempted to find a way to mitigate this problem. However, the detection of fake news spreaders across OSNs remains a challenge. In this paper, we have provided a comprehensive survey of the state of art methods for detecting malicious users and bots based on different features proposed in our novel taxonomy. We have also aimed to avert the crucial problem of fake news detection by discussing several key challenges and potential future research areas to help researchers who are new to this field.}
}
@article{Shao_Menczer_NatComm2018,
	title        = {{The spread of low-credibility content by social bots}},
	author       = {{Shao, Chengcheng and Ciampaglia, Giovanni Luca and Varol, Onur and Yang, Kai Cheng and Flammini, Alessandro and Menczer, Filippo}},
	year         = 2018,
	journal      = {Nature Communications},
	publisher    = {Springer US},
	volume       = 9,
	number       = 1,
	doi          = {https://doi.org/10.1038/s41467-018-06930-7},
	issn         = 20411723,
	url          = {http://dx.doi.org/10.1038/s41467-018-06930-7},
	eprint       = {1707.07592},
	pmid         = 30459415,
	abstract     = {The massive spread of digital misinformation has been identified as a major threat to democracies. Communication, cognitive, social, and computer scientists are studying the complex causes for the viral diffusion of misinformation, while online platforms are beginning to deploy countermeasures. Little systematic, data-based evidence has been published to guide these efforts. Here we analyze 14 million messages spreading 400 thousand articles on Twitter during ten months in 2016 and 2017. We find evidence that social bots played a disproportionate role in spreading articles from low-credibility sources. Bots amplify such content in the early spreading moments, before an article goes viral. They also target users with many followers through replies and mentions. Humans are vulnerable to this manipulation, resharing content posted by bots. Successful low-credibility sources are heavily supported by social bots. These results suggest that curbing social bots may be an effective strategy for mitigating the spread of online misinformation.},
	archiveprefix = {arXiv},
	arxivid      = {1707.07592}
}
@article{Shaw2021,
	title        = {{Do the Online Activities of Amazon Mechanical Turk Workers Mirror Those of the General Population? A Comparison of Two Survey Samples}},
	author       = {{Shaw, Aaron and Hargittai, Eszter}},
	year         = 2021,
	journal      = {International Journal of Communication},
	volume       = 15,
	pages        = {4383--4398},
	url          = {http://ijoc.org.},
	abstract     = {Amazon Mechanical Turk (AMT) offers a relatively low-cost alternative to traditional expensive survey samples, which likely explains its popularity among survey researchers. An important question about using such samples is whether they are representative of the larger Internet user population. Though prior research has addressed this question about demographic characteristics, little work has examined how AMT workers compare with others regarding their online activities—namely, social media experiences and online active engagement. This article analyzes survey data administered concurrently on an AMT and a national sample of U.S. adults to show that AMT workers are significantly more likely to use numerous social media, from Twitter to Pinterest and Reddit, as well as have significantly more experiences contributing their own online content, from posting videos to participating in various online forums and signing online petitions. The article discusses the implications of these findings for research that uses AMT as a sampling frame when examining questions related to social media use and active online engagement.},
	file         = {:Users/qbj218/Dropbox/Laura/Friction Strategies/Lit/Academic/2021{\_}Amazon Mechanical Turk{\_}Sample validity.pdf:pdf},
	keywords     = {administering surveys on the,amazon mechanical turk,data bias,expensive,general population using traditional,helpful alternative with considerably,lower,mail and,methods such as postal,online participation,online samples offer a,phone can be prohibitively,social media use,survey methods}
}
@article{simon1971informationrich,
	title        = {{Designing organizations for an information-rich world}},
	author       = {{Simon, Herbert A and others}},
	year         = 1971,
	journal      = {Computers, communications, and the public interest},
	volume       = 72,
	pages        = 37
}
@software{SimSom,
	title        = {{XXXX}},
	author       = {{XXXX}},
	url          = {xxx},
	version      = {x},
	date         = {x}
}
@article{Sirovich2003,
	title        = {{A pattern analysis of the second Rehnquist U.S. Supreme Court}},
	author       = {{Sirovich, Lawrence}},
	year         = 2003,
	journal      = {Proceedings of the National Academy of Sciences of the United States of America},
	volume       = 100,
	number       = 13,
	pages        = {7432--7437},
	doi          = {https://doi.org/10.1073/pnas.1132164100}
}
@article{SN_ChristoffHansen2015,
	title        = {{A Logic for Diffusion in Social Networks}},
	author       = {{Christoff, Zo\'{e} and Hansen, Jens Ulrik}},
	year         = 2015,
	journal      = {Journal of Applied Logic},
	volume       = 13,
	pages        = {48--77}
}
@inproceedings{SN_christoffhansenlori2013,
	title        = {{A Two-Tiered Formalization of Social Influence}},
	author       = {{Christoff, Zo\'{e} and Hansen, Jens Ulrik}},
	year         = 2013,
	booktitle    = {Logic, Rationality, and Interaction (LORI 2013, Hangzhou)},
	publisher    = {Springer},
	series       = {Lecture Notes in Computer Science},
	volume       = 8196,
	pages        = {68--81},
	editor       = {Grossi, D. and Roy, O. and Huang, H.}
}
@misc{SocialnetworkABM,
	title        = {{Manipulating the Online Marketplace of Ideas}},
	author       = {{Lou, Xiaodan and Flammini, Alessandro and Menczer, Filippo}},
	year         = 2019,
	publisher    = {arXiv},
	doi          = {10.48550/ARXIV.1907.06130},
	url          = {https://arxiv.org/abs/1907.06130}
}
@article{song2022fighting,
	title        = {{Fighting misinformation on social media: effects of evidence type and presentation mode}},
	author       = {{Song, Yunya and Wang, Sai and Xu, Qian}},
	year         = 2022,
	journal      = {Health Education Research},
	publisher    = {Oxford Academic},
	volume       = 37,
	number       = 3,
	pages        = {185--198}
}
@article{Subrahmanian2016,
	title        = {{The DARPA Twitter Bot Challenge}},
	author       = {{Subrahmanian, V. S. and Azaria, Amos and Durst, Skylar and Kagan, Vadim and Galstyan, Aram and Lerman, Kristina and Zhu, Linhong and Ferrara, Emilio and Flammini, Alessandro and Menczer, Filippo}},
	year         = 2016,
	journal      = {Computer},
	publisher    = {IEEE},
	volume       = 49,
	number       = 6,
	pages        = {38--46},
	doi          = {https://doi.ieeecomputersociety.org/10.1109/MC.2016.183},
	issn         = {00189162},
	keywords     = {anomaly detection,intrusion detection,malware mitigation,security,social networks}
}
@article{Suchacka2019,
	title        = {{Improving Clustering Of Web Bot And Human Sessions By Applying Principal Component Analysis}},
	author       = {{Suchacka, Gra\.{z}yna}},
	year         = 2019,
	journal      = {Communications of the ECMS},
	volume       = 33,
	number       = 1,
	doi          = {https://doi.org/10.1016/j.knosys.2020.105875}
}
@article{Suchacka2020,
	title        = {{Identifying legitimate Web users and bots with different traffic profiles -- an Information Bottleneck approach}},
	author       = {{Suchacka, Gra\.{z}yna and Iwa\'{n}ski, Jacek}},
	year         = 2020,
	journal      = {Knowledge-Based Systems},
	volume       = 197,
	pages        = {1--18}
}
@article{SUNSTEIN2020,
	title        = {{Sludge Audits}},
	author       = {{Sunstein, Cass R.}},
	year         = 2020,
	journal      = {Behavioural Public Policy},
	pages        = {1--20},
	doi          = {10.1017/bpp.2019.32},
	issn         = {2398-063X},
	abstract     = {Consumers, employees, students and others are often subjected to ‘sludge': excessive or unjustified frictions, such as paperwork burdens, that cost time or money; that may make life difficult to navigate; that may be frustrating, stigmatizing or humiliating; and that might end up depriving people of access to important goods, opportunities and services. Because of behavioral biases and cognitive scarcity, sludge can have much more harmful effects than private and public institutions anticipate. To protect consumers, investors, employees and others, firms and private and public institutions should regularly conduct Sludge Audits to catalogue the costs of sludge and to decide when and how to reduce it. Sludge often has costs far in excess of benefits, and it can hurt the most vulnerable members of society.},
	file         = {:Users/qbj218/Dropbox/Laura/Friction Strategies/Lit/Academic/2019{\_}Sunstein sludge{\_}audits.pdf:pdf}
}
@book{Surowiecki,
	title        = {{Doubleday}},
	author       = {{Surowiecki, James}},
	year         = 2004,
	publisher    = {The Wisdom of Crowds}
}
@book{surowiecki2005wisdom,
	title        = {{The wisdom of crowds}},
	author       = {{Surowiecki, James}},
	year         = 2005,
	publisher    = {Anchor}
}
@incollection{Takacs2019,
	title        = {{Dormant bots in social media: Twitter and the 2018 U.S. senate election}},
	author       = {{Takacs, Richard and McCulloh, Ian}},
	year         = 2019,
	booktitle    = {Proceedings of the 2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2019},
	pages        = {796--800},
	doi          = {https://doi.org/10.1145/3341161.3343852}
}
@article{thero2022facebook,
	title        = {{Investigating Facebook's interventions against accounts that repeatedly share misinformation}},
	author       = {{Th\'e}ro, H{\'e}lo{\"\i}se and Vincent, Emmanuel M}}}},
	year         = 2022,
	journal      = {Information Processing \& Management},
	publisher    = {Elsevier},
	volume       = 59,
	number       = 2,
	pages        = 102804
}
@article{thero2022investigating,
	title        = {{Investigating Facebook’s interventions against accounts that repeatedly share misinformation}},
	author       = {{Th\'e}ro, H{\'e}lo{\"\i}se and Vincent, Emmanuel M}}}},
	year         = 2022,
	journal      = {Information Processing \& Management},
	publisher    = {Elsevier},
	volume       = 59,
	number       = 2,
	pages        = 102804
}
@article{Tibshirani2001,
	title        = {{Estimating the number of clusters in a data set via the gap statistic}},
	author       = {{Tibshirani, Robert and Walther, Guenther and Hastie, Trevor}},
	year         = 2001,
	journal      = {Journal of the Royal Statistical Society Series B},
	volume       = 63,
	number       = {Part 2},
	pages        = {411--423},
	doi          = {https://doi.org/10.1111/1467-9868.00293}
}
@article{Tomalin2022friction,
	title        = {{Rethinking online friction in the information society}},
	author       = {{Marcus Tomalin}},
	year         = 2022,
	journal      = {Journal of Information Technology},
	volume       = {January 2022},
	doi          = {10.1177/02683962211067812}
}
@inproceedings{Torres-Lugo_Likes_Manip_deletions,
	title        = {{Manipulating Twitter Through Deletions}},
	author       = {{Torres-Lugo, Christopher and Pote, Manita and Nwala, Alexander and Menczer, Filippo}},
	year         = {forthcoming 2022},
	booktitle    = {Proceedings of the 16th International AAAI Conference on Web and Social Media (ICWSM)},
	keywords     = {Social and Information Networks (cs.SI), Computers and Society (cs.CY), FOS: Computer and information sciences, FOS: Computer and information sciences}
}
@article{traberg2022psychological,
	title        = {{Psychological inoculation against misinformation: Current evidence and future directions}},
	author       = {{Traberg, Cecilie S and Roozenbeek, Jon and van der Linden, Sander}},
	year         = 2022,
	journal      = {The ANNALS of the American Academy of Political and Social Science},
	publisher    = {SAGE Publications Sage CA: Los Angeles, CA},
	volume       = 700,
	number       = 1,
	pages        = {136--151}
}
@article{tumminello2011statistically,
	title        = {{Statistically validated networks in bipartite complex systems}},
	author       = {{Tumminello, Michele and Micciche, Salvatore and Lillo, Fabrizio and Piilo, Jyrki and Mantegna, Rosario N}},
	year         = 2011,
	journal      = {PloS one},
	publisher    = {Public Library of Science San Francisco, USA},
	volume       = 6,
	number       = 3,
	pages        = {e17994}
}
@article{twibot2022,
	title        = {{Heterogeneity-aware Twitter Bot Detection with Relational Graph Transformers}},
	author       = {{Shangbin Feng and Zhaoxuan Tan and Rui Li and Minnan Luo}},
	year         = {forthcoming 2022},
	journal      = {Proceedings of the Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI 2022)},
	url          = {https://arxiv.org/abs/2109.02927},
	biburl       = {https://dblp.org/rec/journals/corr/abs-2109-02927.bib}
}
@misc{Twittertransp,
	title        = {{Twitter Moderation Research Consortium}},
	note         = {Accessed: 2022-07-05},
	howpublished = {\url{https://transparency.twitter.com/en/reports/information-operations.html}}
}
@article{verma2022ucred,
	title        = {{UCred: fusion of machine learning and deep learning methods for user credibility on social media}},
	author       = {{Verma, Pawan Kumar and Agrawal, Prateek and Madaan, Vishu and Gupta, Charu}},
	year         = 2022,
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer},
	volume       = 12,
	number       = 1,
	pages        = {1--10}
}
@article{VolunteerScience,
	title        = {{Volunteer Science: An Online Laboratory for Experiments in Social Psychology}},
	author       = {{Jason Radford and Andy Pilny and Ashley Reichelmann and Brian Keegan and Brooke Foucault Welles and Jefferson Hoye and Katherine Ognyanova and Waleed Meleis and David Lazer}},
	year         = 2016,
	journal      = {Social Psychology Quarterly},
	volume       = 79,
	number       = 4,
	pages        = {376--396},
	doi          = {10.1177/0190272516675866},
	url          = {https://doi.org/10.1177/0190272516675866},
	eprint       = {https://doi.org/10.1177/0190272516675866},
	abstract     = {Experimental research in traditional laboratories comes at a significant logistic and financial cost while drawing data from demographically narrow populations. The growth of online methods of research has resulted in effective means for social psychologists to collect large-scale survey-based data in a cost-effective and timely manner. However, the same advancement has not occurred for social psychologists who rely on experimentation as their primary method of data collection. The aim of this article is to provide an overview of one online laboratory for conducting experiments, Volunteer Science, and report the results of six studies that test canonical behaviors commonly captured in social psychological experiments. Our results show that the online laboratory is capable of performing a variety of studies with large numbers of diverse volunteers. We advocate for the use of the online laboratory as a valid and cost-effective way to perform social psychological experiments with large numbers of diverse subjects.}
}
@article{Vosoughi2018,
	title        = {{The spread of true and false news online}},
	year         = 2018,
	journal      = {Science},
	volume       = 359,
	pages        = {1146--1151}
}
@article{vosoughi2018spread,
	title        = {{The spread of true and false news online}},
	author       = {{Vosoughi, Soroush and Roy, Deb and Aral, Sinan}},
	year         = 2018,
	journal      = {science},
	publisher    = {American Association for the Advancement of Science},
	volume       = 359,
	number       = 6380,
	pages        = {1146--1151}
}
@book{wakker2010,
	title        = {{Prospect Theory}},
	author       = {{Wakker, Peter}},
	year         = 2010,
	publisher    = {Cambridge {U}niversity {P}ress}
}
@article{Waldrop12631,
	title        = {{News Feature: The genuine problem of fake news}},
	author       = {{Waldrop, M. Mitchell}},
	year         = 2017,
	journal      = {Proceedings of the National Academy of Sciences},
	publisher    = {National Academy of Sciences},
	volume       = 114,
	number       = 48,
	pages        = {12631--12634},
	doi          = {10.1073/pnas.1719005114},
	issn         = {0027-8424},
	url          = {https://www.pnas.org/content/114/48/12631},
	eprint       = {https://www.pnas.org/content/114/48/12631.full.pdf}
}
@article{Wangmisinfotweets2021,
	title        = {{Analyzing behavioral changes of Twitter users after exposure to misinformation}},
	author       = {{Wang, Yichen and Han, Richard and Lehman, Tamara and Lv, Qin and Mishra, Shivakant}},
	year         = 2021,
	month        = {Nov},
	journal      = {Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
	publisher    = {ACM},
	doi          = {10.1145/3487351.3492718},
	url          = {http://dx.doi.org/10.1145/3487351.3492718}
}
@article{weber2021amplifyingcoord,
	title        = {{Amplifying influence through coordinated behaviour in social networks}},
	author       = {{Weber, Derek and Neumann, Frank}},
	year         = 2021,
	journal      = {Social Network Analysis and Mining},
	publisher    = {Springer},
	volume       = 11,
	number       = 1,
	pages        = {1--42},
	doi          = {https://doi.org/10.1007/s13278-021-00815-2}
}
@article{WeChat2018,
	title        = {{Modelling of information diffusion on social networks with applications to WeChat}},
	author       = {{Liang Liu and Bo Qu and Bin Chen and Alan Hanjalic and Huijuan Wang}},
	year         = 2018,
	journal      = {Physica A: Statistical Mechanics and its Applications},
	volume       = 496,
	pages        = {318--329},
	issn         = {0378-4371}
}
@article{WEF2018,
	title        = {{The Global Risk Report}},
	author       = {{World Economic Forum}},
	year         = 2018,
	journal      = {World Economic Forum (weforum.org)},
	url          = {http://www3.weforum.org/docs/WEF_GRR18_Report.pdf}
}
@article{weng2012competition,
	title        = {{Competition among memes in a world with limited attention}},
	author       = {{Weng, Lilian and Flammini, Alessandro and Vespignani, Alessandro and Menczer, Fillipo}},
	year         = 2012,
	journal      = {Scientific reports},
	publisher    = {Nature Publishing Group},
	volume       = 2,
	number       = 1,
	pages        = {1--9}
}
@inproceedings{Weng2013_triadicclosure,
	title        = {{The Role of Information Diffusion in the Evolution of Social Networks}},
	author       = {{Weng, Lilian and Ratkiewicz, Jacob and Perra, Nicola and Gon\c{c}alves, Bruno and Castillo, Carlos and Bonchi, Francesco and Schifanella, Rossano and Menczer, Filippo and Flammini, Alessandro}},
	year         = 2013,
	location     = {Chicago, Illinois, USA},
	publisher    = {Association for Computing Machinery},
	address      = {New York, NY, USA},
	series       = {KDD '13},
	pages        = {356--364},
	doi          = {10.1145/2487575.2487607},
	isbn         = 9781450321747,
	url          = {https://doi.org/10.1145/2487575.2487607}
}
@misc{Wilensky_Netlogo1999,
	title        = {{NetLogo}},
	author       = {{Wilensky, Uri}},
	year         = 1999,
	url          = {\url{http://ccl.northwestern.edu/netlogo/}},
	note         = {{C}enter for {C}onnected {L}earning and {C}omputer-{B}ased {M}odeling, {N}orthwestern {U}niversity, {E}vanston, IL.}
}
@article{XIAO2017,
	title        = {{Exact algorithms for maximum independent set}},
	author       = {{Mingyu Xiao and Hiroshi Nagamochi}},
	year         = 2017,
	journal      = {Information and Computation},
	volume       = 255,
	pages        = {126--146}
}
@article{yan2022botlandscape,
	title        = {{The landscape of social bot research: a critical appraisal}},
	author       = {{Yan, Harry Yaojun and Yang, Kai-Cheng}},
	year         = 2022,
	publisher    = {OSF Preprints}
}
@article{Yang2019,
	title        = {{Arming the public with artificial intelligence to counter social bots}},
	author       = {{Kai Cheng Yang and Onur Varol and Clayton A. Davis and Emilio Ferrara and Alessandro Flammini and Filippo Menczer}},
	year         = 2019,
	month        = 1,
	journal      = {Human Behavior and Emerging Technologies},
	publisher    = {John Wiley and Sons Inc},
	volume       = 1,
	pages        = {48--61},
	doi          = {https://doi.org/10.1002/hbe2.115},
	issn         = 25781863,
	url          = {http://arxiv.org/abs/1911.09179 http://dx.doi.org/10.1609/aaai.v34i01.5460},
	issue        = 1,
	keywords     = {social influence,social media,social networking},
	abstract     = {The increased relevance of social media in our daily life has been accompanied by efforts to manipulate online conversations and opinions. Deceptive social bots—automated or semi-automated accounts designed to impersonate humans—have been successfully exploited for these kinds of abuse. Researchers have responded by developing artificial intelligence (AI) tools to arm the public in the fight against social bots. Here we review the literature on different types of bots, their impact, and detection methods. We use the case study of Botometer, a popular bot detection tool developed at Indiana University, to illustrate how people interact with AI countermeasures. A user experience survey suggests that bot detection has become an integral part of the social media experience for many users. However, barriers in interpreting the output of AI tools can lead to fundamental misunderstandings. The arms race between machine learning methods to develop sophisticated bots and effective countermeasures makes it necessary to update the training data and features of detection tools. We again use the Botometer case to illustrate both algorithmic and interpretability improvements of bot scores, designed to meet user expectations. We conclude by discussing how future AI developments may affect the fight between malicious bots and the public.}
}
@inproceedings{Yang2020,
	title        = {{Scalable and generalizable social bot detection through data selection}},
	author       = {{Yang, Kai-Cheng and Varol, Onur and Hui, Pik-Mai and Menczer, Filippo}},
	year         = 2020,
	booktitle    = {Proceedings of the AAAI conference on artificial intelligence},
	volume       = 34,
	number       = {01},
	pages        = {1096--1103},
	doi          = {https://doi.org/10.1609/aaai.v34i01.5460}
}
@article{Yang2020_1dim_congress,
	title        = {{Why are U.S. parties so polarized? A "satisficing" dynamical model}},
	author       = {{Yang, Vicky Chuqiao and Abrams, Daniel M. and Kernell, Georgia and Motter, Adilson E.}},
	year         = 2020,
	journal      = {SIAM Review},
	volume       = 62,
	number       = 3,
	pages        = {646--657},
	doi          = {https://doi.org/10.1137/19M1254246}
}
@article{Yang2022,
	title        = {{Botometer 101: Social bot practicum for computational social scientists}},
	author       = {{Kai-Cheng Yang and Emilio Ferrara and Filippo Menczer}},
	year         = 2022,
	month        = 1,
	url          = {http://arxiv.org/abs/2201.01608},
	abstract     = {Social bots have become an important component of online social media. Deceptive bots, in particular, can manipulate online discussions of important issues ranging from elections to public health, threatening the constructive exchange of information. Their ubiquity makes them an interesting research subject and requires researchers to properly handle them when conducting studies using social media data. Therefore it is important for researchers to gain access to bot detection tools that are reliable and easy to use. This paper aims to provide an introductory tutorial of Botometer, a public tool for bot detection on Twitter, for readers who are new to this topic and may not be familiar with programming and machine learning. We introduce how Botometer works, the different ways users can access it, and present a case study as a demonstration. Readers can use the case study code as a template for their own research. We also discuss recommended practice for using Botometer.}
}
@inproceedings{Yashkina_etal_trust_metrics,
	title        = {{Expressing Trust with Temporal Frequency of User Interaction in Online Communities}},
	author       = {{Yashkina, Ekaterina and Pinigin, Arseny and Lee, JooYoung and Mazzara, Manuel and Adekotujo, Akinlolu Solomon and Zubair, Adam and Longo, Luca}},
	year         = 2020,
	booktitle    = {Advanced Information Networking and Applications},
	publisher    = {Springer International Publishing},
	address      = {Cham},
	pages        = {1133--1146},
	editor       = {Barolli, Leonard and Takizawa, Makoto and Xhafa, Fatos and Enokido, Tomoya}
}
@techreport{Yasseri2021Wiki,
	title        = {{Can the Wikipedia moderation model rescue the social marketplace of ideas?}},
	author       = {{Yasseri, Taha and Menczer, Filippo}},
	year         = 2021,
	number       = {2104.13754},
	url          = {https://arxiv.org/abs/2104.13754},
	date-added   = {2021-04-29 16:03:24 -0400},
	date-modified = {2021-04-29 16:05:11 -0400},
	institution  = {arXiv},
	keywords     = {abuse myown osome social crowdsourcing networks web},
	type         = {Preprint},
	bdsk-url-1   = {https://arxiv.org/abs/2104.10635}
}
@article{Yoon2022,
	title        = {{Super-amplifiers! The role of Twitter extended party networks in political elections}},
	author       = {{Nara Yoon and Jeff Hemsley and Alexander Smith and Ellen Simpson and James Eakins}},
	year         = 2022,
	journal      = {Policy and Internet},
	publisher    = {John Wiley and Sons Inc},
	doi          = {10.1002/poi3.295},
	issn         = 19442866,
	keywords     = {Twitter,extended party networks,message diffusion,super-amplifiers,virality},
	abstract     = {Modern election campaigns leverage social media and the networks within to get their messages directly out to the public. We use the theory of extended party networks to explore networks of engaged users who extensively amplify messages posted by political candidates. Using Twitter data from the Senate races in the U.S. 2018 midterm election, we build Twitter extended party networks out of dedicated amplifiers to understand how those engaged users associate with the candidate message amplification. Results show that certain super-amplifiers have a disproportionately large impact on information flows, and that decentralized networks with higher rates of follower reciprocity are associated with higher rates of message diffusion. Our study also finds some support for the idea that super-amplifiers engage in coordinated efforts to diffuse political messages.}
}

@inproceedings{Ng_coordination22,
author = {Ng, Lynnette Hui Xian and Carley, Kathleen M.},
title = {Online Coordination: Methods and Comparative Case Studies of Coordinated Groups across Four Events in the United States},
year = {2022},
isbn = {9781450391917},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501247.3531542},
doi = {10.1145/3501247.3531542},
abstract = {Coordinated groups of user accounts working together in online social media can be used to manipulate the online discourse and thus is an important area of study. In this study, we work towards a general theory of coordination. There are many ways to coordinate groups online: semantic, social, referral and many more. Each represents a coordination dimension, where the more dimensions of coordination are present for one event, the stronger the coordination present. We build on existing approaches that detect coordinated groups by identifying high levels of synchronized actions within a specified time window. A key concern with this approach is the selection of the time window. We propose a method that selects the optimal window size to accurately capture local coordination while avoiding the capture of coincidental synchronicity. With this enhanced method of coordination detection, we perform a comparative study across four events: US Elections Primaries 2020, Reopen America 2020, Capitol Riots 2021 and COVID Vaccine Release 2021. Herein, we explore the following three dimensions of coordination for each event – semantic, referral and social coordination – and perform group and user analysis within and among the events. This allows us to expose different user coordination behavior patterns and identify narratives and user support themes, hence estimating the degree and theme of coordination.},
booktitle = {14th ACM Web Science Conference 2022},
pages = {12–21},
numpages = {10},
keywords = {coordination detection, narrative analysis, social network analysis, URL analysis, community clustering},
location = {Barcelona, Spain},
series = {WebSci '22}
}
